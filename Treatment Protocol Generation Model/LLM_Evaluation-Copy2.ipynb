{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a607cb2c-1ac1-4904-9953-a8a34697daec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c15413-b5ac-42c3-8da5-e7ff8832efb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Standard Library Imports ===\n",
    "import csv\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "from datetime import datetime\n",
    "\n",
    "# === Data Handling ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Utilities & Progress Bars ===\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# === Evaluation Metrics ===\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# === Machine Learning & Embeddings ===\n",
    "import faiss\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# === OpenAI & Azure OpenAI ===\n",
    "import openai\n",
    "import tiktoken\n",
    "from openai import AzureOpenAI, OpenAIError, RateLimitError\n",
    "from langchain_openai import AzureOpenAI as LangchainAzureOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "# === Google Gemini ===\n",
    "import google.generativeai as genai\n",
    "\n",
    "# === RAGAS Evaluation ===\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness\n",
    ")\n",
    "\n",
    "# === ChromaDB ===\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# === PDF Handling ===\n",
    "import pdfplumber\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# === Web & API Requests ===\n",
    "import requests\n",
    "from bs4 import BeautifulSoup  # pip install beautifulsoup4\n",
    "\n",
    "# === Web Scraping (Selenium) ===\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# === Custom Modules ===\n",
    "from LLM_functions import *\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c83aa31-d0f5-4ef1-ad47-fa5a300f65e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Configure Azure OpenAI ===\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://gpt-maa-tm.openai.azure.com/\")  \n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o-mini\")  \n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1f64d0d75ff846c2b01981562a3de602\")  \n",
    "\n",
    "# Inicializar o cliente do Azure OpenAI Service com autenticaÃ§Ã£o baseada em chave    \n",
    "client = AzureOpenAI(  \n",
    "    azure_endpoint=endpoint,  \n",
    "    api_key=subscription_key,  \n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "# Configure Azure OpenAI Embeddings\n",
    "embedding_function = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    azure_deployment=\"TextEmbeddings\",  # Ensure this is the correct deployment name in Azure\n",
    "    openai_api_version=\"2025-01-01-preview\",  # Match the API version\n",
    "    max_retries=50\n",
    ")\n",
    "\n",
    "# === Configure Gemini API ===\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\", \"AIzaSyBUy7-DPerwoKdf1P-7DfAmRsgGuTSXwE0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f03e0f-4c31-48dd-86de-35c0be17f3aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e420a09-5cd3-4ab0-971d-8bd3d3fcad3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Gemini embeddings: 1327\n",
      "Total MiniLM embeddings: 1837\n",
      "Total OpenAI embeddings: 1327\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve all stored embeddings\n",
    "def load_all_embeddings(db):\n",
    "    stored_data = db._collection.get(include=['documents', 'embeddings', 'metadatas'])\n",
    "    return stored_data\n",
    "\n",
    "\n",
    "db_gemini = Chroma(persist_directory=\"/Users/catarinasilva/Desktop/Master Thesis/lung_cancer/LLM lung cancer/embedings/chroma_db_gemini\")\n",
    "db_minilm = Chroma(persist_directory=\"/Users/catarinasilva/Desktop/Master Thesis/lung_cancer/LLM lung cancer/embedings/chroma_db_minilm\")\n",
    "db_openai = Chroma(persist_directory=\"/Users/catarinasilva/Desktop/Master Thesis/lung_cancer/LLM lung cancer/embedings/chroma_db_openAI\")\n",
    "\n",
    "\n",
    "# Load stored embeddings\n",
    "stored_gemini = load_all_embeddings(db_gemini)\n",
    "stored_minilm = load_all_embeddings(db_minilm)\n",
    "stored_openai = load_all_embeddings(db_openai)\n",
    "\n",
    "# Print count of stored embeddings\n",
    "print(f\"Total Gemini embeddings: {len(stored_gemini['documents'])}\")\n",
    "print(f\"Total MiniLM embeddings: {len(stored_minilm['documents'])}\")\n",
    "print(f\"Total OpenAI embeddings: {len(stored_openai['documents'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b696d24-602b-4a44-b913-4ac3fc9baea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Embedding Dimensions: 768\n",
      "MiniLM Embedding Dimensions: 384\n",
      "Open AI Embedding Dimensions: 1536\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a single stored embedding to check dimensions\n",
    "sample_gemini = db_gemini._collection.get(include=[\"embeddings\"], limit=1)\n",
    "sample_minilm = db_minilm._collection.get(include=[\"embeddings\"], limit=1)\n",
    "sample_openai= db_openai._collection.get(include=[\"embeddings\"], limit=1)\n",
    "\n",
    "# Extract the first embedding from each (if available)\n",
    "print(\"Gemini Embedding Dimensions:\", len(sample_gemini[\"embeddings\"][0]))\n",
    "print(\"MiniLM Embedding Dimensions:\", len(sample_minilm[\"embeddings\"][0]))\n",
    "print(\"Open AI Embedding Dimensions:\", len(sample_openai[\"embeddings\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa59339-39a5-47f8-a14f-42a15c612812",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieval methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76ff0192-8afc-43e7-ab8f-e825bcc27b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_top_k_chromadb(query, chromadb_collection, top_k=7):\n",
    "    \"\"\"Retrieves top-K most relevant documents using ChromaDB's cosine similarity search.\"\"\"\n",
    "    \n",
    "    # Fetch stored documents\n",
    "    stored_data = chromadb_collection.get(include=['documents'])\n",
    "\n",
    "    # Ensure documents exist\n",
    "    if \"documents\" not in stored_data or not stored_data[\"documents\"]:\n",
    "        print(\"No documents found in ChromaDB.\")\n",
    "        return []\n",
    "\n",
    "    return stored_data[\"documents\"][:top_k]  # Return top-K documents\n",
    "\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def hybrid_retrieval(query, chromadb_collection, top_k=7):\n",
    "    \"\"\"Combines BM25 lexical search with ChromaDB semantic search.\"\"\"\n",
    "\n",
    "    # Fetch stored documents\n",
    "    stored_data = chromadb_collection.get(include=['documents'])\n",
    "\n",
    "    if \"documents\" not in stored_data or not stored_data[\"documents\"]:\n",
    "        print(\"No documents found in ChromaDB.\")\n",
    "        return []\n",
    "\n",
    "    # Extract documents\n",
    "    corpus_texts = stored_data[\"documents\"]\n",
    "\n",
    "    # BM25 Lexical Search\n",
    "    tokenized_corpus = [doc.split() for doc in corpus_texts]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    # Sort by BM25 scores and return top-k documents\n",
    "    sorted_docs = sorted(zip(corpus_texts, bm25_scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [doc[0] for doc in sorted_docs[:top_k]]\n",
    "\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def combined_retrieval(query, chromadb_collection, top_k=7):\n",
    "    \"\"\"\n",
    "    Combines BM25 lexical search with ChromaDB semantic search.\n",
    "    \n",
    "    - BM25 retrieves keyword-matching documents.\n",
    "    - ChromaDB retrieves semantically similar documents.\n",
    "    - The final list merges both results, prioritizing unique and relevant documents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch stored documents\n",
    "    stored_data = chromadb_collection.get(include=['documents'])\n",
    "\n",
    "    if \"documents\" not in stored_data or not stored_data[\"documents\"]:\n",
    "        print(\"No documents found in ChromaDB.\")\n",
    "        return []\n",
    "\n",
    "    # Extract documents\n",
    "    corpus_texts = stored_data[\"documents\"]\n",
    "\n",
    "    # ðŸ”¹ BM25 Lexical Search\n",
    "    tokenized_corpus = [doc.split() for doc in corpus_texts]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    # Sort by BM25 scores and return top-k documents\n",
    "    sorted_docs = sorted(zip(corpus_texts, bm25_scores), key=lambda x: x[1], reverse=True)\n",
    "    retrieved_bm25_docs = [doc[0] for doc in sorted_docs[:top_k]]\n",
    "\n",
    "    # ðŸ”¹ ChromaDB Semantic Search\n",
    "    retrieved_chromadb_docs = retrieve_top_k_chromadb(query, chromadb_collection, top_k=top_k)\n",
    "\n",
    "    # Combine results (Union of BM25 + ChromaDB), ensuring no duplicates\n",
    "    combined_docs = list(dict.fromkeys(retrieved_bm25_docs + retrieved_chromadb_docs))  # Maintains order\n",
    "\n",
    "    # Return only top-k results\n",
    "    return combined_docs[:top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3050c1-dc95-48b5-9882-5f07ca2908db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d5afcc-6334-4a67-a5c5-75cbf4caa5b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c318eb0-37cf-4d10-8d99-7fdc9951bb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_structured_prompt_tnm(t_stage, n_stage, m_stage, histopath_grade, cancer_type, age, gender, additional_info=None):\n",
    "    \"\"\"\n",
    "    Generates a structured medical prompt for the Gemini RAG system to classify lung cancer \n",
    "    based on TNM staging and guide an evidence-based treatment strategy.\n",
    "    Ensures independent logic for NSCLC and SCLC, and guides response structure accordingly.\n",
    "\n",
    "    Parameters:\n",
    "    - t_stage (str): Tumor stage (T).\n",
    "    - n_stage (str): Lymph node involvement (N).\n",
    "    - m_stage (str): Metastasis stage (M).\n",
    "    - histopath_grade (str): Tumor differentiation grade.\n",
    "    - cancer_type (str): Type of lung cancer (e.g., \"Adenocarcinoma\", \"Squamous Cell Carcinoma\", \"Small Cell Lung Cancer\").\n",
    "    - age (int): Patient's age.\n",
    "    - gender (str): Patient's gender.\n",
    "    - additional_info (str, optional): Other relevant factors (e.g., \"Smoker\", \"Comorbidities\").\n",
    "\n",
    "    Returns:\n",
    "    - str: A structured and detailed medical prompt for evidence-based reasoning and response generation.\n",
    "    \"\"\"\n",
    "\n",
    "    common_info = f\"\"\"\n",
    "You are a clinical oncology assistant specialized in lung cancer.\n",
    "\n",
    "Your tasks:\n",
    "1. **Determine the clinical TNM stage** (Iâ€“IV, including substages A, B, or C) based on the AJCC 8th Edition staging system.\n",
    "2. **Generate a structured, evidence-based treatment plan** according to the stage, histology, and type of lung cancer.\n",
    "3. **Use only information derived from retrieved clinical guidelines and peer-reviewed literature** to support your reasoning.\n",
    "4. **Do not assume facts outside the provided information.**\n",
    "5. **Use specific medical terminology**, and name all **treatments, radiotherapy modalities, and chemotherapy/immunotherapy regimens explicitly** when referenced in guidelines.\n",
    "\n",
    "---\n",
    "\n",
    "### Patient Information\n",
    "- **Type of Cancer:** {cancer_type}\n",
    "- **Age:** {age}\n",
    "- **Gender:** {gender}\n",
    "- **Tumor (T) Stage:** {t_stage}\n",
    "- **Lymph Node (N) Stage:** {n_stage}\n",
    "- **Metastasis (M) Stage:** {m_stage}\n",
    "- **Histopathological Grade:** {histopath_grade}\n",
    "{f\"- **Additional Clinical Factors:** {additional_info}\" if additional_info else \"\"}\n",
    "\"\"\"\n",
    "\n",
    "    nsclc_prompt = \"\"\"\n",
    "---\n",
    "\n",
    "### TNM Staging Classification (NSCLC)\n",
    "- Classify the patientâ€™s cancer into the correct clinical stage using the TNM (AJCC 8th Edition) system.\n",
    "- You must always specify the substage letter (A, B, or C) when reporting the stage. For example: Stage IIA, Stage IIIB, Stage IVA,  Stage IVB.\n",
    "- Justify the staging using anatomical and clinical criteria from validated guidelines.\n",
    "\n",
    "---\n",
    "\n",
    "### Evidence-Based Treatment Strategy (NSCLC)\n",
    "Structure your response based on the clinical stage:\n",
    "\n",
    "- **Stage Iâ€“II**: Guide curative options such as surgery, stereotactic body radiation therapy (SBRT), neoadjuvant/adjuvant chemotherapy. Evaluate patient fitness and comorbidities.\n",
    "\n",
    "- **Stage III**: \n",
    "    - Distinguish between resectable and unresectable disease. \n",
    "    - Guide multimodal approaches including concurrent chemoradiotherapy, neoadjuvant therapy, or surgical resection with adjuvant therapy. \n",
    "    - Include biomarker-driven therapies (e.g., EGFR, ALK, ROS1, PD-L1, BRAF).\n",
    "\n",
    "- **Stage IV**: Guide systemic treatment approaches:\n",
    "  - Specify line of therapy (first-line, second-line, refractory)\n",
    "  - Define histologic subtype and performance status\n",
    "  - Include molecular marker-based treatment (e.g., EGFR inhibitors, ALK inhibitors, PD-L1 checkpoint inhibitors)\n",
    "\n",
    "- **Non-Surgical Management**: Describe alternative definitive approaches such as SBRT, hypofractionated EBRT, or systemic therapy alone.\n",
    "\n",
    "- **Clinical Trials**: Indicate when enrollment is recommended.\n",
    "\n",
    "- **Palliative Care**: Include symptom control, psychosocial support, and advanced care planning.\n",
    "\n",
    "- **Follow-Up and Surveillance**: Provide guideline-driven recommendations for imaging, biomarker monitoring, and toxicity management.\n",
    "\"\"\"\n",
    "\n",
    "    sclc_prompt = f\"\"\"\n",
    "---\n",
    "\n",
    "### TNM and Traditional Stage Classification (SCLC)\n",
    "- Classify the patientâ€™s cancer using the AJCC 8th Edition TNM system.\n",
    "- Based on TNM and anatomical considerations, determine whether the patient has:\n",
    "  - **Limited-Stage SCLC (LS-SCLC)**\n",
    "  - **Extensive-Stage SCLC (ES-SCLC)**\n",
    "- Justify classification using validated criteria from clinical staging references.\n",
    "\n",
    "---\n",
    "\n",
    "### Evidence-Based Treatment Strategy (SCLC)\n",
    "Structure your response based on SCLC stage:\n",
    "\n",
    "- **Limited-Stage SCLC (LS-SCLC)**:\n",
    "  - Recommend **concurrent chemoradiation** using **etoposide + cisplatin or carboplatin**, combined with **thoracic radiation therapy (TRT)**.\n",
    "  - Indicate when **surgical resection** (e.g., lobectomy) may be considered for T1â€“T2, N0 cases.\n",
    "  - Include use of **prophylactic cranial irradiation (PCI)** in patients with complete/near-complete response to initial treatment.\n",
    "  - Mention **durvalumab** as consolidation therapy if supported by recent clinical evidence.\n",
    "\n",
    "- **Extensive-Stage SCLC (ES-SCLC)**:\n",
    "  - Recommend systemic therapy.\n",
    "  - Specify use of **thoracic radiation** in responders, and **PCI or MRI surveillance**.\n",
    "\n",
    "- **Non-Surgical Management**:\n",
    "  - Emphasize chemotherapy and radiation-based treatment regimens.\n",
    "  - Provide alternatives (e.g., sequential chemoradiation or chemotherapy alone) for patients with poor performance status or comorbidities.\n",
    "\n",
    "- **Older Adults (â‰¥70 years)** only if age above 70:\n",
    "  - Evaluate treatment tolerance based on comorbidities and performance status.\n",
    "  - Adjust treatment intensity accordingly.\n",
    "  - Highlight higher risks of **hematologic toxicity** and **treatment-related mortality** with standard chemoradiotherapy.\n",
    "  - Mention use of **supportive care**, dose-reduction strategies, or monotherapy if clinically indicated.\n",
    "  - Include data on survival equivalence in older adults who complete standard therapy and caution when extrapolating trial data.\n",
    "\n",
    "- **Clinical Trials**:\n",
    "  - Highlight ongoing investigations into immunotherapy, radiotherapy fractionation, and novel agents.\n",
    "\n",
    "- **Palliative Care**:\n",
    "  - Include symptom management for brain metastases, superior vena cava syndrome, and paraneoplastic syndromes.\n",
    "  - Discuss early integration of palliative services.\n",
    "\n",
    "- **Follow-Up and Surveillance**:\n",
    "  - Recommend the followup strategies for SCLC based on the stage (mention the time frequence and need for CT scans).\n",
    "  - Say what needs to be monitored (e.g.,Chemotherapy-related toxicities)\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "    final_questions = \"\"\"\n",
    "---\n",
    "\n",
    "### Final Structured Output\n",
    "Include the following:\n",
    "\n",
    "1. **Clinical Stage**: AJCC TNM stage and, if SCLC, Limited or Extensive stage classification.\n",
    "2. **Treatment Plan**: Structured by stage and supported by current clinical guidelines.\n",
    "3. **Therapeutic Modalities**: Use specific names of chemotherapy agents, radiotherapy modalities (e.g., PCI, TRT), and immunotherapies.\n",
    "4. **Clinical Trial Considerations**: Identify trial opportunities based on disease state and patient factors.\n",
    "5. **Palliative and Supportive Care**: Describe symptom-focused care and when it should be integrated.\n",
    "6. **Follow-Up Plan**: Provide evidence-based recommendations for surveillance and survivorship care.\n",
    "\"\"\"\n",
    "\n",
    "    if \"small cell carcinoma\" in cancer_type.lower():\n",
    "        prompt = common_info + sclc_prompt + final_questions\n",
    "    else:\n",
    "        prompt = common_info + nsclc_prompt + final_questions\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf91e39-0d56-404f-baab-c24fa853e490",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model set up (Gemini 2.0 flash and GPT-4o-mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b93df9-a6f5-405d-ab17-24799719776c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def generate_response_gpt4o(context, query):\n",
    "    \"\"\"Generates a response using GPT-4o-mini.\"\"\"\n",
    "    endpoint = os.getenv(\"ENDPOINT_URL\", \"https://gpt-maa-tm.openai.azure.com/\")  \n",
    "    deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o-mini\")  \n",
    "    subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1f64d0d75ff846c2b01981562a3de602\")  \n",
    "\n",
    "    # Inicializar o cliente do Azure OpenAI Service com autenticaÃ§Ã£o baseada em chave    \n",
    "    client = AzureOpenAI(  \n",
    "        azure_endpoint=endpoint,  \n",
    "        api_key=subscription_key,  \n",
    "        api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a medical AI specializing in lung cancer staging and treatment planning.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Query: {query}\\n\\n{context}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "def generate_response_gemini(context, query):\n",
    "    \"\"\"Generates a response using Gemini 2.0 Flash based on structured TNM staging prompt.\"\"\"\n",
    "    genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\", \"AIzaSyAsBeecsEuVOeo7zanoC7yfC5w97hi4ffM\"))\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    response = model.generate_content(f\"Query: {query}\\n\\n{context}\")\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df129e8-edb2-4604-9e07-7db5a9f2f7b0",
   "metadata": {},
   "source": [
    "### Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c413f23-67dc-49a3-bfa8-765cdda9e567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieval_and_response_pipeline(\n",
    "    query, \n",
    "    embedding_model, \n",
    "    retrieval_method,  # Now supports 'cosine', 'bm25', and 'combined'\n",
    "    llm_model, \n",
    "    t_stage, \n",
    "    n_stage, \n",
    "    m_stage, \n",
    "    histopath_grade, \n",
    "    cancer_type, \n",
    "    age, \n",
    "    gender, \n",
    "    additional_info=None, \n",
    "    top_k=10  # Increased default to allow better ranking\n",
    "):\n",
    "    \"\"\"Runs the full pipeline: retrieval â†’ structured TNM prompt â†’ response generation.\"\"\"\n",
    "    \n",
    "    # Select ChromaDB collection based on embedding model\n",
    "    if embedding_model == \"gemini\":\n",
    "        chromadb_collection = db_gemini\n",
    "    elif embedding_model == \"minilm\":\n",
    "        chromadb_collection = db_minilm\n",
    "    elif embedding_model == \"openai\":\n",
    "        chromadb_collection = db_openai\n",
    "    else:\n",
    "        raise ValueError(\"Invalid embedding model. Choose from 'gemini', 'minilm', or 'openai'.\")\n",
    "\n",
    "    # Retrieve relevant documents based on the selected method\n",
    "    if retrieval_method == \"cosine\":\n",
    "        retrieved_docs = retrieve_top_k_chromadb(query, chromadb_collection, top_k=top_k)\n",
    "    elif retrieval_method == \"bm25\":\n",
    "        retrieved_docs = hybrid_retrieval(query, chromadb_collection, top_k=top_k)\n",
    "    elif retrieval_method == \"combined\":\n",
    "        retrieved_docs = combined_retrieval(query, chromadb_collection, top_k=top_k)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid retrieval method. Choose from 'cosine', 'bm25', or 'combined'.\")\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        return \"No relevant documents found in ChromaDB.\"\n",
    "\n",
    "    # Generate structured TNM staging prompt with patient-specific details\n",
    "    structured_prompt = generate_structured_prompt_tnm(\n",
    "        t_stage, n_stage, m_stage, histopath_grade, cancer_type, age, gender, additional_info\n",
    "    )\n",
    "\n",
    "    retrieved_context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "    # Create the final structured prompt\n",
    "    final_prompt = f\"{structured_prompt}\\n\\n### **Retrieved Guidelines & Literature**\\n{retrieved_context}\"\n",
    "\n",
    "    # Generate response using selected LLM\n",
    "    if llm_model == \"gpt-4o\":\n",
    "        response = generate_response_gpt4o(final_prompt, query)\n",
    "    elif llm_model == \"gemini\":\n",
    "        response = generate_response_gemini(final_prompt, query)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid LLM model. Choose from 'gpt-4o' or 'gemini'.\")\n",
    "\n",
    "    return response, retrieved_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32542bd6-dce2-4bde-853e-432b185737c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3636ea5-94f2-40e9-9620-e07670a070cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RAGAS setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "814e801f-8a35-4ff1-a707-1a9189a6c618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# LLM (Azure GPT)\n",
    "llm = LangchainLLMWrapper(\n",
    "    AzureChatOpenAI(\n",
    "        deployment_name=\"gpt-4o-mini\",  # Nome do deployment no Azure\n",
    "        azure_endpoint=\"https://gpt-maa-tm.openai.azure.com/\",  # Endpoint do recurso\n",
    "        api_key=\"1f64d0d75ff846c2b01981562a3de602\",  # Chave do Azure\n",
    "        api_version=\"2025-01-01-preview\",\n",
    "        timeout=120\n",
    "    )\n",
    ")\n",
    "\n",
    "# Embeddings (Azure Text Embedding)\n",
    "embeddings = LangchainEmbeddingsWrapper(\n",
    "    AzureOpenAIEmbeddings(\n",
    "        model=\"TextEmbeddings\",\n",
    "        azure_endpoint=\"https://gpt-maa-tm.openai.azure.com/\",\n",
    "        api_key=\"1f64d0d75ff846c2b01981562a3de602\",\n",
    "        api_version=\"2025-01-01-preview\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Configure as variÃ¡veis do Azure OpenAI diretamente\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"1f64d0d75ff846c2b01981562a3de602\"  # sua chave secreta\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://gpt-maa-tm.openai.azure.com/\"  # seu endpoint\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2025-01-01-preview\"  # versÃ£o da API\n",
    "os.environ[\"OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4o-mini\"  # nome do deployment no Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018f5b7-28c6-4e68-9d2a-495b891eac8b",
   "metadata": {},
   "source": [
    "#### Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1389f2c0-58b8-4d62-8e71-1da57b9cc4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Patient Stage Matching =========\n",
      "\n",
      "[âœ”] Patient 0: TNM: T1a-N0-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IA**\n",
      "[âœ”] Patient 1: TNM: T1b-N0-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IA**\n",
      "[âœ”] Patient 2: TNM: T1c-N0-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IA**\n",
      "[âœ”] Patient 3: TNM: T2a-N0-M0 | Type: Large cell â†’ Matched Stage: **IB**\n",
      "[âœ”] Patient 4: TNM: T2b-N0-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIA**\n",
      "[âœ”] Patient 5: TNM: T1a-N1-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIB**\n",
      "[âœ”] Patient 6: TNM: T1b-N1-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIB**\n",
      "[âœ”] Patient 7: TNM: T1c-N1-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIB**\n",
      "[âœ”] Patient 8: TNM: T2a-N1-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIB**\n",
      "[âœ”] Patient 9: TNM: T2b-N1-M0 | Type: Large cell â†’ Matched Stage: **IIB**\n",
      "[âœ”] Patient 10: TNM: T3-N0-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIB**\n",
      "[âœ”] Patient 11: TNM: T1a-N2-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 12: TNM: T1b-N2-M0 | Type: Large cell â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 13: TNM: T1c-N2-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 14: TNM: T2a-N2-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 15: TNM: T2b-N2-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 16: TNM: T3-N1-M0 | Type: Large cell â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 17: TNM: T4-N0-M0 | Type: Large cell â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 18: TNM: T4-N1-M0 | Type: Large cell â†’ Matched Stage: **IIIA**\n",
      "[âœ”] Patient 19: TNM: T1a-N3-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIIB**\n",
      "[âœ”] Patient 20: TNM: T1b-N3-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIIB**\n",
      "[âœ”] Patient 21: TNM: T1c-N3-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIIB**\n",
      "[âœ”] Patient 22: TNM: T2a-N3-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIIB**\n",
      "[âœ”] Patient 23: TNM: T2b-N3-M0 | Type: Adenocarcinoma â†’ Matched Stage: **IIIB**\n",
      "[âœ”] Patient 24: TNM: T3-N2-M0 | Type: Large cell â†’ Matched Stage: **IIIB**\n",
      "[âœ”] Patient 25: TNM: T4-N2-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIIB**\n",
      "[âœ”] Patient 26: TNM: T3-N3-M0 | Type: Large cell â†’ Matched Stage: **IIIC**\n",
      "[âœ”] Patient 27: TNM: T4-N3-M0 | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IIIC**\n",
      "[âœ”] Patient 28: TNM: T2a-N3-M1a | Type: Adenocarcinoma â†’ Matched Stage: **IVA**\n",
      "[âœ”] Patient 29: TNM: T2b-N3-M1b | Type: Adenocarcinoma â†’ Matched Stage: **IVA**\n",
      "[âœ”] Patient 30: TNM: T3-N3-M1c | Type: Squamus Cell Carcinoma â†’ Matched Stage: **IVB**\n",
      "[âœ”] Patient 31: TNM: T2-N3-M0 | Age: 66 | Type: Small Cell Carcinoma â†’ Matched Stage: **LS-SCLC**\n",
      "[âœ”] Patient 32: TNM: T2-N3-M0 | Age: 53 | Type: Small Cell Carcinoma â†’ Matched Stage: **LS-SCLC**\n",
      "[âœ”] Patient 33: TNM: T1a-N0-M0 | Age: 73 | Type: Small Cell Carcinoma â†’ Matched Stage: **LS-SCLC**\n",
      "[âœ”] Patient 34: TNM: T3-N1-M1 | Age: 61 | Type: Small Cell Carcinoma â†’ Matched Stage: **ES-SCLC**\n",
      "[âœ”] Patient 35: TNM: T3-N3-M1b | Age: 73 | Type: Small Cell Carcinoma â†’ Matched Stage: **ES-SCLC**\n",
      "\n",
      "Resumo: 36 pacientes com estÃ¡gio atribuÃ­do | 0 sem correspondÃªncia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminhos dos ficheiros\n",
    "GROUND_TRUTH_PATH = \"/Users/catarinasilva/Desktop/Lung_Cancer_Treatment_Stages_Final.csv\"\n",
    "INPUT_PATIENTS_PATH = \"/Users/catarinasilva/Desktop/patient_inputs_sample.csv\"\n",
    "\n",
    "# Carregar datasets\n",
    "def load_ground_truth():\n",
    "    df = pd.read_csv(GROUND_TRUTH_PATH, sep=\";\", engine=\"python\")\n",
    "    df.columns = [\"Cancer Type\", \"T-Stage\", \"N-Stage\", \"M-Stage\", \"Stage\", \"Age\", \"Treatment Plan\"]\n",
    "    df.dropna(subset=[\"T-Stage\", \"N-Stage\", \"M-Stage\", \"Stage\", \"Treatment Plan\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_patient_inputs():\n",
    "    return pd.read_csv(INPUT_PATIENTS_PATH, sep=\";\")\n",
    "\n",
    "# VerificaÃ§Ã£o do matching\n",
    "def test_stage_matching():\n",
    "    gt = load_ground_truth()\n",
    "    patients = load_patient_inputs()\n",
    "\n",
    "    matched = []\n",
    "    unmatched = []\n",
    "\n",
    "    print(\"\\n========= Patient Stage Matching =========\\n\")\n",
    "\n",
    "    for idx, row in patients.iterrows():\n",
    "        t = str(row[\"T_stage\"]).strip()\n",
    "        n = str(row[\"N_stage\"]).strip()\n",
    "        m = str(row[\"M_stage\"]).strip()\n",
    "        cancer_type = str(row[\"cancer_type\"])\n",
    "        age = int(row[\"age\"])\n",
    "\n",
    "        # SCLC: Matching com mÃºltiplos valores por linha e faixa etÃ¡ria\n",
    "        if \"SMALL CELL\" in cancer_type.upper():\n",
    "            match_found = False\n",
    "            for _, ref in gt[gt[\"Cancer Type\"].str.upper().str.contains(\"SMALL CELL\")].iterrows():\n",
    "                t_vals = [v.strip() for v in str(ref[\"T-Stage\"]).split(\";\")]\n",
    "                n_vals = [v.strip() for v in str(ref[\"N-Stage\"]).split(\";\")]\n",
    "                m_vals = [v.strip() for v in str(ref[\"M-Stage\"]).split(\";\")]\n",
    "                age_label = str(ref[\"Age\"]).strip()\n",
    "\n",
    "                t_match = \"Any T\" in t_vals or t in t_vals\n",
    "                n_match = \"Any N\" in n_vals or n in n_vals\n",
    "                m_match = \"Any M\" in m_vals or m in m_vals or any(m == mv for mv in m_vals)\n",
    "                age_group = \">= 70\" if age >= 70 else \"< 70\"\n",
    "\n",
    "                if t_match and n_match and m_match and age_label == age_group:\n",
    "                    stage = ref[\"Stage\"]\n",
    "                    matched.append((idx, stage))\n",
    "                    print(f\"[âœ”] Patient {idx}: TNM: {t}-{n}-{m} | Age: {age} | Type: {cancer_type} â†’ Matched Stage: **{stage}**\")\n",
    "                    match_found = True\n",
    "                    break\n",
    "\n",
    "            if not match_found:\n",
    "                unmatched.append((idx, t, n, m, cancer_type))\n",
    "                print(f\"[âœ–] Patient {idx}: No SCLC match for TNM: {t}-{n}-{m} | Age: {age} | Type: {cancer_type}\")\n",
    "\n",
    "        # NSCLC: matching direto ou por regras de M1\n",
    "        else:\n",
    "            if m in [\"M1a\", \"M1b\", \"M1c\"]:\n",
    "                match = gt[\n",
    "                    (gt[\"M-Stage\"] == m) &\n",
    "                    (gt[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                    (gt[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "                ]\n",
    "            elif m == \"M1\":\n",
    "                match = gt[\n",
    "                    (gt[\"M-Stage\"].str.startswith(\"M1\")) &\n",
    "                    (gt[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                    (gt[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "                ]\n",
    "            else:\n",
    "                match = gt[\n",
    "                    (gt[\"T-Stage\"] == t) &\n",
    "                    (gt[\"N-Stage\"] == n) &\n",
    "                    (gt[\"M-Stage\"] == m)\n",
    "                ]\n",
    "\n",
    "            if match.empty:\n",
    "                unmatched.append((idx, t, n, m, cancer_type))\n",
    "                print(f\"[âœ–] Patient {idx}: No NSCLC match for TNM: {t}-{n}-{m} | Type: {cancer_type}\")\n",
    "            else:\n",
    "                stage = match.iloc[0][\"Stage\"]\n",
    "                matched.append((idx, stage))\n",
    "                print(f\"[âœ”] Patient {idx}: TNM: {t}-{n}-{m} | Type: {cancer_type} â†’ Matched Stage: **{stage}**\")\n",
    "\n",
    "    print(f\"\\nResumo: {len(matched)} pacientes com estÃ¡gio atribuÃ­do | {len(unmatched)} sem correspondÃªncia\\n\")\n",
    "\n",
    "    return matched, unmatched\n",
    "\n",
    "# Executar o teste\n",
    "matched, unmatched = test_stage_matching()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f57c3-f20d-41fa-a326-ffb5b0462dcd",
   "metadata": {},
   "source": [
    "##### Evaluation GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc18756-2666-4a7a-9818-970c8ea094e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ========== #\n",
    "GROUND_TRUTH_PATH = \"/Users/catarinasilva/Desktop/Lung_Cancer_Treatment_Stages_Final.csv\"\n",
    "INPUT_PATIENTS_PATH = \"/Users/catarinasilva/Desktop/patient_inputs_sample.csv\"\n",
    "N_REPEATS = 10\n",
    "EMBEDDING_MODELS = [\"gemini\", \"minilm\", \"openai\"]\n",
    "RETRIEVAL_METHODS = [\"cosine\", \"bm25\", \"combined\"]\n",
    "LLM_MODELS = [\"gpt-4o\"] #, \"gemini\"\n",
    "OUTPUT_PATH = \"/Users/catarinasilva/Desktop/LLM/repeated_evaluation_results.csv\"\n",
    "SUMMARY_PATH = \"/Users/catarinasilva/Desktop/LLM/evaluation_summary.csv\"\n",
    "GROUPED_PATH = \"/Users/catarinasilva/Desktop/LLM/retrieval_strategy_comparison.csv\"\n",
    "\n",
    "# ========== STAGE & TREATMENT EXTRACTION ========== #\n",
    "def extract_stage_and_treatment(generated_output):\n",
    "    text = generated_output.upper()\n",
    "    predicted_stage = None\n",
    "\n",
    "    # SCLC classification (robust version)\n",
    "    if re.search(r\"\\b(EXTENSIVE[\\s\\-]?STAGE|ES\\-SCLC)\\b\", text):\n",
    "        predicted_stage = \"ES-SCLC\"\n",
    "    elif re.search(r\"\\b(LIMITED[\\s\\-]?STAGE|LS\\-SCLC)\\b\", text):\n",
    "        predicted_stage = \"LS-SCLC\"\n",
    "    else:\n",
    "        # NSCLC staging extraction: Look for full Stage declaration (e.g., \"Stage IA\")\n",
    "        stage_matches = re.findall(r\"\\bSTAGE\\s+(I{1,3}|IV)([ABC])?\\b\", text)\n",
    "        if stage_matches:\n",
    "            # Build full stage string (e.g., 'IA', 'IIIB', etc.)\n",
    "            stages = [f\"{m[0]}{m[1] or ''}\" for m in stage_matches]\n",
    "            predicted_stage = stages[-1]  # Take the last matched stage\n",
    "        else:\n",
    "            # Fallback: Check for exact TNM grouping (e.g., \"T1a, N0, M0\") and infer known combinations\n",
    "            tnms = re.search(r\"\\bT\\d[AaBb]?,?\\s*N\\d[AaBb]?,?\\s*M\\d[AaBb]?\\b\", text)\n",
    "            if tnms:\n",
    "                # Optional: integrate logic to map TNM to stage using AJCC rules, if needed\n",
    "                predicted_stage = None  # placeholder if future logic needed\n",
    "\n",
    "    # Treatment extraction (same as before, robust)\n",
    "    treatment_match = re.split(r\"(?i)treatment plan:|appropriate treatment plan is:\", generated_output)\n",
    "    predicted_treatment = treatment_match[1].strip() if len(treatment_match) > 1 else generated_output.strip()\n",
    "\n",
    "    return predicted_stage, predicted_treatment\n",
    "\n",
    "# ======= Rate limit control ========== #\n",
    "REQUEST_TIMESTAMPS = deque()\n",
    "TOKENS_USED = 0\n",
    "MAX_REQUESTS_PER_MINUTE = 2500\n",
    "MAX_TOKENS_PER_MINUTE = 250000\n",
    "\n",
    "def enforce_rate_limits(token_count):\n",
    "    \"\"\"Dynamically enforce OpenAI rate limits before making a request.\"\"\"\n",
    "    global REQUEST_TIMESTAMPS, TOKENS_USED\n",
    "    current_time = time.time()\n",
    "\n",
    "    while REQUEST_TIMESTAMPS and (current_time - REQUEST_TIMESTAMPS[0]) > 60:\n",
    "        REQUEST_TIMESTAMPS.popleft()\n",
    "\n",
    "    requests_remaining = MAX_REQUESTS_PER_MINUTE - len(REQUEST_TIMESTAMPS)\n",
    "    tokens_remaining = MAX_TOKENS_PER_MINUTE - TOKENS_USED\n",
    "\n",
    "    if requests_remaining <= 0 or tokens_remaining < token_count:\n",
    "        if REQUEST_TIMESTAMPS:\n",
    "            sleep_time = max(1, 60 - (current_time - REQUEST_TIMESTAMPS[0]))\n",
    "        else:\n",
    "            sleep_time = 60\n",
    "        print(f\"Rate limit reached. Sleeping for {sleep_time:.2f} seconds.\")\n",
    "        time.sleep(sleep_time)\n",
    "        TOKENS_USED = 0\n",
    "\n",
    "    REQUEST_TIMESTAMPS.append(current_time)\n",
    "    TOKENS_USED += token_count\n",
    "\n",
    "# ========== LOAD DATA ========== #\n",
    "def load_ground_truth():\n",
    "    df = pd.read_csv(GROUND_TRUTH_PATH, sep=\";\", engine=\"python\")\n",
    "    df.columns = [\"Cancer Type\", \"T-Stage\", \"N-Stage\", \"M-Stage\", \"Stage\", \"Age\", \"Treatment Plan\"]\n",
    "    df.dropna(subset=[\"T-Stage\", \"N-Stage\", \"M-Stage\", \"Stage\", \"Treatment Plan\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_patient_inputs():\n",
    "    df = pd.read_csv(INPUT_PATIENTS_PATH, sep=';')\n",
    "    expected_cols = {\"T_stage\", \"N_stage\", \"M_stage\", \"age\", \"Gender\", \"smoking_status\", \"cancer_type\"}\n",
    "    if not expected_cols.issubset(set(df.columns)):\n",
    "        raise ValueError(f\"Missing columns in input file. Required: {expected_cols}\")\n",
    "    return df\n",
    "\n",
    "# ========== MAIN FUNCTION ========== #\n",
    "def run_evaluation_pipeline():\n",
    "    test_set = load_ground_truth()\n",
    "    patient_inputs = load_patient_inputs()\n",
    "    all_results = []\n",
    "    ragas_records_map = defaultdict(list)\n",
    "\n",
    "    for idx, patient in tqdm(patient_inputs.iterrows(), total=len(patient_inputs)):\n",
    "        t_stage = patient[\"T_stage\"]\n",
    "        n_stage = patient[\"N_stage\"]\n",
    "        m_stage = patient[\"M_stage\"]\n",
    "        age = int(patient[\"age\"])\n",
    "        cancer_type = patient[\"cancer_type\"]\n",
    "\n",
    "        if \"SMALL CELL\" in cancer_type.upper():\n",
    "            # Matching para SCLC\n",
    "            stage_found = False\n",
    "            for _, row in test_set[test_set[\"Cancer Type\"].str.upper().str.contains(\"SMALL CELL\")].iterrows():\n",
    "                t_vals = [v.strip() for v in row[\"T-Stage\"].split(\";\")]\n",
    "                n_vals = [v.strip() for v in row[\"N-Stage\"].split(\";\")]\n",
    "                m_vals = [v.strip() for v in row[\"M-Stage\"].split(\";\")]\n",
    "                age_label = row[\"Age\"].strip()\n",
    "\n",
    "                t_match = \"Any T\" in t_vals or t_stage in t_vals\n",
    "                n_match = \"Any N\" in n_vals or n_stage in n_vals\n",
    "                m_match = \"Any M\" in m_vals or m_stage in m_vals or any(m_stage == mv for mv in m_vals)\n",
    "\n",
    "                age_group = \">= 70\" if age >= 70 else \"< 70\"\n",
    "\n",
    "                if t_match and n_match and m_match and age_group == age_label:\n",
    "                    true_stage = row[\"Stage\"]\n",
    "                    true_treatment = row[\"Treatment Plan\"]\n",
    "                    stage_found = True\n",
    "                    break\n",
    "\n",
    "            if not stage_found:\n",
    "                print(f\"[Warning] No SCLC match for TNM: {t_stage}, {n_stage}, {m_stage} and age: {age}\")\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            # Matching para NSCLC\n",
    "            match = test_set[\n",
    "                (test_set[\"T-Stage\"] == t_stage) &\n",
    "                (test_set[\"N-Stage\"] == n_stage) &\n",
    "                (test_set[\"M-Stage\"] == m_stage)\n",
    "            ]\n",
    "\n",
    "            # Se nÃ£o encontrar, tenta fallback com \"Any\"\n",
    "            if match.empty and m_stage in [\"M1a\", \"M1b\", \"M1c\"]:\n",
    "                match = test_set[\n",
    "                    (test_set[\"M-Stage\"] == m_stage) &\n",
    "                    ((test_set[\"T-Stage\"] == \"Any T\") | test_set[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                    ((test_set[\"N-Stage\"] == \"Any N\") | test_set[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "                ]\n",
    "            elif match.empty and m_stage == \"M1\":\n",
    "                match = test_set[\n",
    "                    (test_set[\"M-Stage\"].str.startswith(\"M1\")) &\n",
    "                    ((test_set[\"T-Stage\"] == \"Any T\") | test_set[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                    ((test_set[\"N-Stage\"] == \"Any N\") | test_set[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "                ]\n",
    "\n",
    "            if match.empty:\n",
    "                print(f\"[Warning] No NSCLC match for TNM: {t_stage}, {n_stage}, {m_stage}\")\n",
    "                continue\n",
    "\n",
    "            true_stage = match.iloc[0][\"Stage\"]\n",
    "            true_treatment = match.iloc[0][\"Treatment Plan\"]\n",
    "\n",
    "        age = int(patient[\"age\"])\n",
    "        cancer_type = patient[\"cancer_type\"]\n",
    "        smoker = patient[\"smoking_status\"]\n",
    "        gender = patient[\"Gender\"]\n",
    "        additional_info = f\"Smoker: {'Yes' if smoker else 'No'}\"\n",
    "        \n",
    "        for embedding_model in EMBEDDING_MODELS:\n",
    "            for retrieval_method in RETRIEVAL_METHODS:\n",
    "                for llm_model in LLM_MODELS:\n",
    "                    for run_idx in range(N_REPEATS):\n",
    "                        max_retries = 1\n",
    "                        retry_delay = 15  # segundos\n",
    "\n",
    "                        success = False\n",
    "                        for attempt in range(max_retries):\n",
    "                            try:\n",
    "                                enforce_rate_limits(6000)\n",
    "                                response, retrieved_docs = retrieval_and_response_pipeline(\n",
    "                                    query=\"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                                    embedding_model=embedding_model,\n",
    "                                    retrieval_method=retrieval_method,\n",
    "                                    llm_model=llm_model,\n",
    "                                    t_stage=t_stage,\n",
    "                                    n_stage=n_stage,\n",
    "                                    m_stage=m_stage,\n",
    "                                    histopath_grade=\"\",\n",
    "                                    cancer_type=cancer_type,\n",
    "                                    age=age,\n",
    "                                    gender=gender,\n",
    "                                    additional_info=additional_info\n",
    "                                )\n",
    "\n",
    "                                if response and not str(response).startswith(\"ERROR\"):\n",
    "                                    success = True\n",
    "                                    break  # sucesso, sair do loop\n",
    "                            except Exception as e:\n",
    "                                print(f\"[âŒ Attempt {attempt+1}/{max_retries}] API Error: {e}\")\n",
    "\n",
    "                            print(f\"[â³ Attempt {attempt+1}/{max_retries}] Retrying in {retry_delay} seconds...\")\n",
    "                            time.sleep(retry_delay)\n",
    "\n",
    "                        if not success:\n",
    "                            print(f\"[ðŸš¨] Failed after {max_retries} retries. Skipping input_idx={idx}.\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "                        pred_stage, pred_treatment = extract_stage_and_treatment(response)\n",
    "\n",
    "                        all_results.append({\n",
    "                            \"input_idx\": idx,\n",
    "                            \"run_idx\": run_idx,\n",
    "                            \"embedding_model\": embedding_model,\n",
    "                            \"retrieval_method\": retrieval_method,\n",
    "                            \"llm_model\": llm_model,\n",
    "                            \"T_stage\": t_stage,\n",
    "                            \"N_stage\": n_stage,\n",
    "                            \"M_stage\": m_stage,\n",
    "                            \"cancer_type\": cancer_type,\n",
    "                            \"true_stage\": true_stage,\n",
    "                            \"predicted_stage\": pred_stage,\n",
    "                            \"ground_truth_answer\": true_treatment,\n",
    "                            \"predicted_treatment\": pred_treatment,\n",
    "                            \"raw_output\": response,\n",
    "                            \"contexts\": retrieved_docs\n",
    "                        })\n",
    "\n",
    "                        combo_key = (embedding_model, retrieval_method, llm_model)\n",
    "                        ragas_records_map[combo_key].append({\n",
    "                            \"question\": \"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                            \"answer\": response,\n",
    "                            \"contexts\": retrieved_docs,\n",
    "                            \"ground_truths\": [true_treatment],\n",
    "                            \"reference\": true_treatment\n",
    "                        })\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df[\"stage_match\"] = results_df[\"true_stage\"] == results_df[\"predicted_stage\"]\n",
    "    \n",
    "    results_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved results to {OUTPUT_PATH}\")\n",
    "\n",
    "    print(\"Computing RAGAS...\")\n",
    "    # ========= RAGAS ========= #\n",
    "    ragas_summary = []\n",
    "    for combo_key, records in ragas_records_map.items():\n",
    "        embedding_model, retrieval_method, llm_model = combo_key\n",
    "        ragas_dataset = Dataset.from_list(records)\n",
    "\n",
    "\n",
    "        ragas_result = evaluate(\n",
    "            dataset=ragas_dataset,\n",
    "            metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "            llm=llm,\n",
    "            embeddings=embeddings\n",
    "        )\n",
    "        \n",
    "        ragas_summary.append({\n",
    "            \"embedding_model\": embedding_model,\n",
    "            \"retrieval_method\": retrieval_method,\n",
    "            \"llm_model\": llm_model,\n",
    "            \"RAGAS_Faithfulness\": np.nanmean(ragas_result[\"faithfulness\"]),\n",
    "            \"RAGAS_AnswerRelevancy\": np.nanmean(ragas_result[\"answer_relevancy\"]),\n",
    "            \"RAGAS_ContextPrecision\": np.nanmean(ragas_result[\"context_precision\"]),\n",
    "            \"RAGAS_ContextRecall\": np.nanmean(ragas_result[\"context_recall\"])\n",
    "        })\n",
    "\n",
    "        mask = (\n",
    "            (results_df[\"embedding_model\"] == embedding_model) &\n",
    "            (results_df[\"retrieval_method\"] == retrieval_method) &\n",
    "            (results_df[\"llm_model\"] == llm_model)\n",
    "        )\n",
    "\n",
    "        for metric in [\"faithfulness\", \"answer_relevancy\", \"context_precision\", \"context_recall\"]:\n",
    "            mean_value = np.nanmean(ragas_result[metric])\n",
    "            results_df.loc[mask, f\"RAGAS_{metric}\"] = mean_value\n",
    "\n",
    "\n",
    "    print(\"Computing BERTScore...\")\n",
    "    preds = results_df[\"predicted_treatment\"].fillna(\"\").tolist()\n",
    "    refs = results_df[\"ground_truth_answer\"].fillna(\"\").tolist()\n",
    "    _, _, f1_scores = bert_score(preds, refs, lang=\"en\", verbose=False, device=\"mps\")\n",
    "    results_df[\"bertscore_f1\"] = f1_scores.numpy()\n",
    "\n",
    "    print(\"Computing BLEU and ROUGE-L...\")\n",
    "    bleu_scores, rouge_l_scores = [], []\n",
    "    smoother = SmoothingFunction()\n",
    "    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    for pred, ref in zip(preds, refs):\n",
    "        bleu = sentence_bleu([ref.split()], pred.split(), smoothing_function=smoother.method1)\n",
    "        rouge_l = rouge.score(ref, pred)[\"rougeL\"].fmeasure\n",
    "        bleu_scores.append(bleu)\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "    results_df[\"bleu\"] = bleu_scores\n",
    "    results_df[\"rougeL\"] = rouge_l_scores\n",
    "\n",
    "\n",
    "    results_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved results to {OUTPUT_PATH}\")\n",
    "    \n",
    "    print(\"Computing Classification Metrics for Staging...\")\n",
    "    valid_results = results_df.dropna(subset=[\"true_stage\", \"predicted_stage\"])\n",
    "    labels = unique_labels(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"])\n",
    "\n",
    "    # Matriz de confusÃ£o com labels fixos\n",
    "    cm = confusion_matrix(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], labels=labels)\n",
    "\n",
    "    # ConstruÃ§Ã£o segura do DataFrame\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm_df.to_csv(\"/Users/catarinasilva/Desktop/LLM/confusion_matrix.csv\")\n",
    "    print(f\"[âœ”] Saved confusion matrix to confusion_matrix.csv\")\n",
    "\n",
    "    cls_report = classification_report(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], output_dict=True, zero_division=0)\n",
    "    cls_report_df = pd.DataFrame(cls_report).transpose()\n",
    "    cls_report_df.to_csv(\"/Users/catarinasilva/Desktop/LLM/classification_report.csv\")\n",
    "    print(f\"[âœ”] Saved classification report to classification_report.csv\")\n",
    "\n",
    "    stage_accuracy = accuracy_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"])\n",
    "    stage_f1_macro = f1_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "    stage_f1_weighted = f1_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='weighted', zero_division=0)\n",
    "    stage_precision_macro = precision_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "    stage_recall_macro = recall_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "    stage_kappa = cohen_kappa_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"])\n",
    "\n",
    "    summary = {\n",
    "        \"Stage Accuracy\": stage_accuracy,\n",
    "        \"Stage F1 Score (Macro)\": stage_f1_macro,\n",
    "        \"Stage F1 Score (Weighted)\": stage_f1_weighted,\n",
    "        \"Stage Precision (Macro)\": stage_precision_macro,\n",
    "        \"Stage Recall (Macro)\": stage_recall_macro,\n",
    "        \"Stage Cohen's Kappa\": stage_kappa,\n",
    "        \"BERTScore F1 (mean)\": results_df[\"bertscore_f1\"].mean(),\n",
    "        \"BLEU Score (mean)\": results_df[\"bleu\"].mean(),\n",
    "        \"ROUGE-L Score (mean)\": results_df[\"rougeL\"].mean(),\n",
    "        \"RAGAS_Faithfulness\": np.nanmean(ragas_result[\"faithfulness\"]),\n",
    "        \"RAGAS_AnswerRelevancy\": np.nanmean(ragas_result[\"answer_relevancy\"]),\n",
    "        \"RAGAS_ContextPrecision\": np.nanmean(ragas_result[\"context_precision\"]),\n",
    "        \"RAGAS_ContextRecall\": np.nanmean(ragas_result[\"context_recall\"])\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([summary]).to_csv(SUMMARY_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved summary to {SUMMARY_PATH}\")\n",
    "\n",
    "    grouped_df = results_df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\"])[\n",
    "        [\"stage_match\", \"bertscore_f1\", \"bleu\", \"rougeL\"]\n",
    "    ].agg([\"mean\", \"std\"]).reset_index()\n",
    "    \n",
    "    grouped_df.columns = ['embedding_model', 'retrieval_method', 'llm_model'] + ['_'.join(col).strip() for col in grouped_df.columns.values[3:]]\n",
    "\n",
    "    # Carrega as mÃ©tricas RAGAS por combinaÃ§Ã£o\n",
    "    ragas_summary_df = pd.DataFrame(ragas_summary)\n",
    "\n",
    "    # Junta as mÃ©tricas por chave\n",
    "    full_grouped = pd.merge(grouped_df, ragas_summary_df, on=[\"embedding_model\", \"retrieval_method\", \"llm_model\"], how=\"left\")\n",
    "\n",
    "    # Salva tudo junto\n",
    "    full_grouped.to_csv(GROUPED_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved grouped metrics including RAGAS to {GROUPED_PATH}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ed6fbe9-c630-4051-9e00-e16e18080f63",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "run_evaluation_pipeline()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db13e543-12d2-4774-9300-01f651268e94",
   "metadata": {},
   "source": [
    "[âœ”] Saved results to /Users/catarinasilva/Desktop/LLM/repeated_evaluation_results.csv\n",
    "Computing Classification Metrics for Staging...\n",
    "[âœ”] Saved confusion matrix to confusion_matrix.csv\n",
    "[âœ”] Saved classification report to classification_report.csv\n",
    "[âœ”] Saved summary to /Users/catarinasilva/Desktop/LLM/evaluation_summary.csv\n",
    "[âœ”] Saved grouped metrics including RAGAS to /Users/catarinasilva/Desktop/LLM/retrieval_strategy_comparison.csv\n",
    "CPU times: user 17min 12s, sys: 1h 22min 36s, total: 1h 39min 49s\n",
    "Wall time: 1d 7h 16min 9s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f4edde-1a5c-442f-a364-ea09c6ce43e0",
   "metadata": {},
   "source": [
    "##### Evaluation Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19d5d82-61dc-4dd3-a39e-b12aef01c3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ========== #\n",
    "GROUND_TRUTH_PATH = \"/Users/catarinasilva/Desktop/Lung_Cancer_Treatment_Stages_Final.csv\"\n",
    "INPUT_PATIENTS_PATH = \"/Users/catarinasilva/Desktop/patient_inputs_sample.csv\"\n",
    "N_REPEATS = 10\n",
    "EMBEDDING_MODELS = [\"gemini\", \"minilm\", \"openai\"]\n",
    "RETRIEVAL_METHODS = [\"cosine\", \"bm25\", \"combined\"]\n",
    "LLM_MODELS = [\"gemini\"]\n",
    "OUTPUT_PATH = \"/Users/catarinasilva/Desktop/LLM/Gemini/repeated_evaluation_results.csv\"\n",
    "SUMMARY_PATH = \"/Users/catarinasilva/Desktop/LLM/Gemini//evaluation_summary.csv\"\n",
    "GROUPED_PATH = \"/Users/catarinasilva/Desktop/LLM/Gemini//retrieval_strategy_comparison.csv\"\n",
    "\n",
    "# ========== STAGE & TREATMENT EXTRACTION ========== #\n",
    "def extract_stage_and_treatment(generated_output):\n",
    "    text = generated_output.upper()\n",
    "    predicted_stage = None\n",
    "\n",
    "    # SCLC classification (robust version)\n",
    "    if re.search(r\"\\b(EXTENSIVE[\\s\\-]?STAGE|ES\\-SCLC)\\b\", text):\n",
    "        predicted_stage = \"ES-SCLC\"\n",
    "    elif re.search(r\"\\b(LIMITED[\\s\\-]?STAGE|LS\\-SCLC)\\b\", text):\n",
    "        predicted_stage = \"LS-SCLC\"\n",
    "    else:\n",
    "        # NSCLC staging extraction: Look for full Stage declaration (e.g., \"Stage IA\")\n",
    "        stage_matches = re.findall(r\"\\bSTAGE\\s+(I{1,3}|IV)([ABC])?\\b\", text)\n",
    "        if stage_matches:\n",
    "            # Build full stage string (e.g., 'IA', 'IIIB', etc.)\n",
    "            stages = [f\"{m[0]}{m[1] or ''}\" for m in stage_matches]\n",
    "            predicted_stage = stages[-1]  # Take the last matched stage\n",
    "        else:\n",
    "            # Fallback: Check for exact TNM grouping (e.g., \"T1a, N0, M0\") and infer known combinations\n",
    "            tnms = re.search(r\"\\bT\\d[AaBb]?,?\\s*N\\d[AaBb]?,?\\s*M\\d[AaBb]?\\b\", text)\n",
    "            if tnms:\n",
    "                # Optional: integrate logic to map TNM to stage using AJCC rules, if needed\n",
    "                predicted_stage = None  # placeholder if future logic needed\n",
    "\n",
    "    # Treatment extraction (same as before, robust)\n",
    "    treatment_match = re.split(r\"(?i)treatment plan:|appropriate treatment plan is:\", generated_output)\n",
    "    predicted_treatment = treatment_match[1].strip() if len(treatment_match) > 1 else generated_output.strip()\n",
    "\n",
    "    return predicted_stage, predicted_treatment\n",
    "\n",
    "# ========== LOAD DATA ========== #\n",
    "def load_ground_truth():\n",
    "    df = pd.read_csv(GROUND_TRUTH_PATH, sep=\";\", engine=\"python\")\n",
    "    df.columns = [\"Cancer Type\", \"T-Stage\", \"N-Stage\", \"M-Stage\", \"Stage\", \"Age\", \"Treatment Plan\"]\n",
    "    df.dropna(subset=[\"T-Stage\", \"N-Stage\", \"M-Stage\", \"Stage\", \"Treatment Plan\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_patient_inputs():\n",
    "    df = pd.read_csv(INPUT_PATIENTS_PATH, sep=';')\n",
    "    expected_cols = {\"T_stage\", \"N_stage\", \"M_stage\", \"age\", \"Gender\", \"smoking_status\", \"cancer_type\"}\n",
    "    if not expected_cols.issubset(set(df.columns)):\n",
    "        raise ValueError(f\"Missing columns in input file. Required: {expected_cols}\")\n",
    "    return df\n",
    "\n",
    "# ========== MAIN FUNCTION ========== #\n",
    "def run_evaluation_pipeline():\n",
    "    test_set = load_ground_truth()\n",
    "    patient_inputs = load_patient_inputs()\n",
    "    all_results = []\n",
    "    ragas_records_map = defaultdict(list)\n",
    "\n",
    "    for idx, patient in tqdm(patient_inputs.iterrows(), total=len(patient_inputs)):\n",
    "        t_stage = patient[\"T_stage\"]\n",
    "        n_stage = patient[\"N_stage\"]\n",
    "        m_stage = patient[\"M_stage\"]\n",
    "        age = int(patient[\"age\"])\n",
    "        cancer_type = patient[\"cancer_type\"]\n",
    "\n",
    "        if \"SMALL CELL\" in cancer_type.upper():\n",
    "            # Matching para SCLC\n",
    "            stage_found = False\n",
    "            for _, row in test_set[test_set[\"Cancer Type\"].str.upper().str.contains(\"SMALL CELL\")].iterrows():\n",
    "                t_vals = [v.strip() for v in row[\"T-Stage\"].split(\";\")]\n",
    "                n_vals = [v.strip() for v in row[\"N-Stage\"].split(\";\")]\n",
    "                m_vals = [v.strip() for v in row[\"M-Stage\"].split(\";\")]\n",
    "                age_label = row[\"Age\"].strip()\n",
    "\n",
    "                t_match = \"Any T\" in t_vals or t_stage in t_vals\n",
    "                n_match = \"Any N\" in n_vals or n_stage in n_vals\n",
    "                m_match = \"Any M\" in m_vals or m_stage in m_vals or any(m_stage == mv for mv in m_vals)\n",
    "\n",
    "                age_group = \">= 70\" if age >= 70 else \"< 70\"\n",
    "\n",
    "                if t_match and n_match and m_match and age_group == age_label:\n",
    "                    true_stage = row[\"Stage\"]\n",
    "                    true_treatment = row[\"Treatment Plan\"]\n",
    "                    stage_found = True\n",
    "                    break\n",
    "\n",
    "            if not stage_found:\n",
    "                print(f\"[Warning] No SCLC match for TNM: {t_stage}, {n_stage}, {m_stage} and age: {age}\")\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            # Matching para NSCLC\n",
    "            match = test_set[\n",
    "                (test_set[\"T-Stage\"] == t_stage) &\n",
    "                (test_set[\"N-Stage\"] == n_stage) &\n",
    "                (test_set[\"M-Stage\"] == m_stage)\n",
    "            ]\n",
    "\n",
    "            # Se nÃ£o encontrar, tenta fallback com \"Any\"\n",
    "            if match.empty and m_stage in [\"M1a\", \"M1b\", \"M1c\"]:\n",
    "                match = test_set[\n",
    "                    (test_set[\"M-Stage\"] == m_stage) &\n",
    "                    ((test_set[\"T-Stage\"] == \"Any T\") | test_set[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                    ((test_set[\"N-Stage\"] == \"Any N\") | test_set[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "                ]\n",
    "            elif match.empty and m_stage == \"M1\":\n",
    "                match = test_set[\n",
    "                    (test_set[\"M-Stage\"].str.startswith(\"M1\")) &\n",
    "                    ((test_set[\"T-Stage\"] == \"Any T\") | test_set[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                    ((test_set[\"N-Stage\"] == \"Any N\") | test_set[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "                ]\n",
    "\n",
    "            if match.empty:\n",
    "                print(f\"[Warning] No NSCLC match for TNM: {t_stage}, {n_stage}, {m_stage}\")\n",
    "                continue\n",
    "\n",
    "            true_stage = match.iloc[0][\"Stage\"]\n",
    "            true_treatment = match.iloc[0][\"Treatment Plan\"]\n",
    "\n",
    "        age = int(patient[\"age\"])\n",
    "        cancer_type = patient[\"cancer_type\"]\n",
    "        smoker = patient[\"smoking_status\"]\n",
    "        gender = patient[\"Gender\"]\n",
    "        additional_info = f\"Smoker: {'Yes' if smoker else 'No'}\"\n",
    "\n",
    "        for embedding_model in EMBEDDING_MODELS:\n",
    "            for retrieval_method in RETRIEVAL_METHODS:\n",
    "                for llm_model in LLM_MODELS:\n",
    "                    for run_idx in range(N_REPEATS):\n",
    "                        max_retries = 2\n",
    "                        retry_delay = 15\n",
    "                        success = False\n",
    "\n",
    "                        for attempt in range(max_retries):\n",
    "                            try:\n",
    "                                response, retrieved_docs = retrieval_and_response_pipeline(\n",
    "                                    query=\"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                                    embedding_model=embedding_model,\n",
    "                                    retrieval_method=retrieval_method,\n",
    "                                    llm_model=llm_model,\n",
    "                                    t_stage=t_stage,\n",
    "                                    n_stage=n_stage,\n",
    "                                    m_stage=m_stage,\n",
    "                                    histopath_grade=\"\",\n",
    "                                    cancer_type=cancer_type,\n",
    "                                    age=age,\n",
    "                                    gender=gender,\n",
    "                                    additional_info=additional_info\n",
    "                                )\n",
    "\n",
    "                                if response and not str(response).startswith(\"ERROR\"):\n",
    "                                    success = True\n",
    "                                    break\n",
    "\n",
    "                            except Exception as e:\n",
    "                                error_message = str(e)\n",
    "                                if \"429\" in error_message:\n",
    "                                    print(\"[ðŸš¨] Quota excedida. Aguardando 24 horas para retomar...\")\n",
    "                                    time.sleep(86410)  # 24 horas = 86400 segundos\n",
    "                                else:\n",
    "                                    print(f\"[âŒ Attempt {attempt+1}/{max_retries}] API Error: {e}\")\n",
    "\n",
    "                            print(f\"[â³ Attempt {attempt+1}/{max_retries}] Retrying in {retry_delay} seconds...\")\n",
    "                            time.sleep(retry_delay)\n",
    "\n",
    "                        if not success:\n",
    "                            print(f\"[ðŸš¨] Failed after {max_retries} retries. Skipping input_idx={idx}.\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "                        pred_stage, pred_treatment = extract_stage_and_treatment(response)\n",
    "\n",
    "                        all_results.append({\n",
    "                            \"input_idx\": idx,\n",
    "                            \"run_idx\": run_idx,\n",
    "                            \"embedding_model\": embedding_model,\n",
    "                            \"retrieval_method\": retrieval_method,\n",
    "                            \"llm_model\": llm_model,\n",
    "                            \"T_stage\": t_stage,\n",
    "                            \"N_stage\": n_stage,\n",
    "                            \"M_stage\": m_stage,\n",
    "                            \"cancer_type\": cancer_type,\n",
    "                            \"true_stage\": true_stage,\n",
    "                            \"predicted_stage\": pred_stage,\n",
    "                            \"ground_truth_answer\": true_treatment,\n",
    "                            \"predicted_treatment\": pred_treatment,\n",
    "                            \"raw_output\": response,\n",
    "                            \"contexts\": retrieved_docs\n",
    "                        })\n",
    "\n",
    "                        combo_key = (embedding_model, retrieval_method, llm_model)\n",
    "                        ragas_records_map[combo_key].append({\n",
    "                            \"question\": \"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                            \"answer\": response,\n",
    "                            \"contexts\": retrieved_docs,\n",
    "                            \"ground_truths\": [true_treatment],\n",
    "                            \"reference\": true_treatment\n",
    "                        })\n",
    "                        \n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df[\"stage_match\"] = results_df[\"true_stage\"] == results_df[\"predicted_stage\"]\n",
    "    \n",
    "    \n",
    "    results_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved results to {OUTPUT_PATH}\")\n",
    "\n",
    "    print(\"Computing RAGAS...\")\n",
    "    # ========= RAGAS ========= #\n",
    "    ragas_summary = []\n",
    "    for combo_key, records in ragas_records_map.items():\n",
    "        embedding_model, retrieval_method, llm_model = combo_key\n",
    "        ragas_dataset = HFDataset.from_list(records)\n",
    "\n",
    "        ragas_result = evaluate(\n",
    "            dataset=ragas_dataset,\n",
    "            metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "            llm=llm,\n",
    "            embeddings=embeddings\n",
    "        )\n",
    "        \n",
    "        ragas_summary.append({\n",
    "            \"embedding_model\": embedding_model,\n",
    "            \"retrieval_method\": retrieval_method,\n",
    "            \"llm_model\": llm_model,\n",
    "            \"RAGAS_Faithfulness\": np.nanmean(ragas_result[\"faithfulness\"]),\n",
    "            \"RAGAS_AnswerRelevancy\": np.nanmean(ragas_result[\"answer_relevancy\"]),\n",
    "            \"RAGAS_ContextPrecision\": np.nanmean(ragas_result[\"context_precision\"]),\n",
    "            \"RAGAS_ContextRecall\": np.nanmean(ragas_result[\"context_recall\"])\n",
    "        })\n",
    "\n",
    "        mask = (\n",
    "            (results_df[\"embedding_model\"] == embedding_model) &\n",
    "            (results_df[\"retrieval_method\"] == retrieval_method) &\n",
    "            (results_df[\"llm_model\"] == llm_model)\n",
    "        )\n",
    "\n",
    "        for metric in [\"faithfulness\", \"answer_relevancy\", \"context_precision\", \"context_recall\"]:\n",
    "            mean_value = np.nanmean(ragas_result[metric])\n",
    "            results_df.loc[mask, f\"RAGAS_{metric}\"] = mean_value\n",
    "\n",
    "\n",
    "    print(\"Computing BERTScore...\")\n",
    "    preds = results_df[\"predicted_treatment\"].fillna(\"\").tolist()\n",
    "    refs = results_df[\"ground_truth_answer\"].fillna(\"\").tolist()\n",
    "    _, _, f1_scores = bert_score(preds, refs, lang=\"en\", verbose=False, device=\"mps\")\n",
    "    results_df[\"bertscore_f1\"] = f1_scores.numpy()\n",
    "\n",
    "    print(\"Computing BLEU and ROUGE-L...\")\n",
    "    bleu_scores, rouge_l_scores = [], []\n",
    "    smoother = SmoothingFunction()\n",
    "    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    for pred, ref in zip(preds, refs):\n",
    "        bleu = sentence_bleu([ref.split()], pred.split(), smoothing_function=smoother.method1)\n",
    "        rouge_l = rouge.score(ref, pred)[\"rougeL\"].fmeasure\n",
    "        bleu_scores.append(bleu)\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "    results_df[\"bleu\"] = bleu_scores\n",
    "    results_df[\"rougeL\"] = rouge_l_scores\n",
    "\n",
    "\n",
    "    results_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved results to {OUTPUT_PATH}\")\n",
    "    \n",
    "    print(\"Computing Classification Metrics for Staging...\")\n",
    "    valid_results = results_df.dropna(subset=[\"true_stage\", \"predicted_stage\"])\n",
    "    labels = unique_labels(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"])\n",
    "\n",
    "    # Matriz de confusÃ£o com labels fixos\n",
    "    cm = confusion_matrix(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], labels=labels)\n",
    "\n",
    "    # ConstruÃ§Ã£o segura do DataFrame\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm_df.to_csv(\"/Users/catarinasilva/Desktop/LLM/confusion_matrix.csv\")\n",
    "    print(f\"[âœ”] Saved confusion matrix to confusion_matrix.csv\")\n",
    "\n",
    "    cls_report = classification_report(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], output_dict=True, zero_division=0)\n",
    "    cls_report_df = pd.DataFrame(cls_report).transpose()\n",
    "    cls_report_df.to_csv(\"/Users/catarinasilva/Desktop/LLM/classification_report.csv\")\n",
    "    print(f\"[âœ”] Saved classification report to classification_report.csv\")\n",
    "\n",
    "    stage_accuracy = accuracy_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"])\n",
    "    stage_f1_macro = f1_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "    stage_f1_weighted = f1_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='weighted', zero_division=0)\n",
    "    stage_precision_macro = precision_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "    stage_recall_macro = recall_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "    stage_kappa = cohen_kappa_score(valid_results[\"true_stage\"], valid_results[\"predicted_stage\"])\n",
    "\n",
    "    summary = {\n",
    "        \"Stage Accuracy\": stage_accuracy,\n",
    "        \"Stage F1 Score (Macro)\": stage_f1_macro,\n",
    "        \"Stage F1 Score (Weighted)\": stage_f1_weighted,\n",
    "        \"Stage Precision (Macro)\": stage_precision_macro,\n",
    "        \"Stage Recall (Macro)\": stage_recall_macro,\n",
    "        \"Stage Cohen's Kappa\": stage_kappa,\n",
    "        \"BERTScore F1 (mean)\": results_df[\"bertscore_f1\"].mean(),\n",
    "        \"BLEU Score (mean)\": results_df[\"bleu\"].mean(),\n",
    "        \"ROUGE-L Score (mean)\": results_df[\"rougeL\"].mean(),\n",
    "        \"RAGAS_Faithfulness\": np.nanmean(ragas_result[\"faithfulness\"]),\n",
    "        \"RAGAS_AnswerRelevancy\": np.nanmean(ragas_result[\"answer_relevancy\"]),\n",
    "        \"RAGAS_ContextPrecision\": np.nanmean(ragas_result[\"context_precision\"]),\n",
    "        \"RAGAS_ContextRecall\": np.nanmean(ragas_result[\"context_recall\"])\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([summary]).to_csv(SUMMARY_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved summary to {SUMMARY_PATH}\")\n",
    "\n",
    "    grouped_df = results_df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\"])[\n",
    "        [\"stage_match\", \"bertscore_f1\", \"bleu\", \"rougeL\"]\n",
    "    ].agg([\"mean\", \"std\"]).reset_index()\n",
    "    \n",
    "    grouped_df.columns = ['embedding_model', 'retrieval_method', 'llm_model'] + ['_'.join(col).strip() for col in grouped_df.columns.values[3:]]\n",
    "\n",
    "    # Carrega as mÃ©tricas RAGAS por combinaÃ§Ã£o\n",
    "    ragas_summary_df = pd.DataFrame(ragas_summary)\n",
    "\n",
    "    # Junta as mÃ©tricas por chave\n",
    "    full_grouped = pd.merge(grouped_df, ragas_summary_df, on=[\"embedding_model\", \"retrieval_method\", \"llm_model\"], how=\"left\")\n",
    "\n",
    "    # Salva tudo junto\n",
    "    full_grouped.to_csv(GROUPED_PATH, index=False)\n",
    "    print(f\"[âœ”] Saved grouped metrics including RAGAS to {GROUPED_PATH}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edf8f239-7e10-451e-99f7-6ee7745ae9ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "run_evaluation_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196f976-b0a0-4880-b708-abefa12b0c86",
   "metadata": {},
   "source": [
    "#### Fix results (GPT & Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4f297ae-982f-4568-9b4c-74aa26f033dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_stage_and_treatment(text):\n",
    "    text = text.upper()\n",
    "    predicted_stage = None\n",
    "\n",
    "    # SCLC classification (robust version)\n",
    "    if re.search(r\"\\b(EXTENSIVE[\\s\\-]?STAGE|ES\\-SCLC)\\b\", text):\n",
    "        predicted_stage = \"ES-SCLC\"\n",
    "    elif re.search(r\"\\b(LIMITED[\\s\\-]?STAGE|LS\\-SCLC)\\b\", text):\n",
    "        predicted_stage = \"LS-SCLC\"\n",
    "    else:\n",
    "        # Detailed stages (IA, IB, etc.) with optional suffix (e.g., IA2)\n",
    "        detailed_stage_pattern = r\"\\b(?:STAGE\\s+)?(I{1,3}|IV)([ABC])\\d?\\b\"\n",
    "        detailed_matches = re.findall(detailed_stage_pattern, text)\n",
    "\n",
    "        if detailed_matches:\n",
    "            stages = [f\"{m[0]}{m[1]}\" for m in detailed_matches]\n",
    "            predicted_stage = stages[-1]\n",
    "        else:\n",
    "            # General stages (I, II, III, IV)\n",
    "            general_stage_pattern = r\"\\b(?:STAGE\\s+)?(I{1,3}|IV)\\b\"\n",
    "            general_matches = re.findall(general_stage_pattern, text)\n",
    "            if general_matches:\n",
    "                predicted_stage = general_matches[-1]\n",
    "\n",
    "    # Extract treatment as fallback\n",
    "    treatment_match = re.split(r\"(?i)treatment plan:|appropriate treatment plan is:\", text)\n",
    "    predicted_treatment = treatment_match[1].strip() if len(treatment_match) > 1 else text.strip()\n",
    "\n",
    "    return predicted_stage, predicted_treatment\n",
    "\n",
    "\n",
    "def correct_predicted_stages(dff):\n",
    "    # Copy the DataFrame to avoid modifying the original\n",
    "    dff = dff.copy()\n",
    "\n",
    "    # Apply correction only where predicted_stage != true_stage\n",
    "    mask = (dff['predicted_stage'] != dff['true_stage']) | dff['predicted_stage'].isna()\n",
    "    for idx, row in dff[mask].iterrows():\n",
    "        new_stage, _ = extract_stage_and_treatment(row['raw_output'])\n",
    "        dff.at[idx, 'predicted_stage'] = new_stage\n",
    "\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f86ef3-c22a-401d-b91c-6c5ae114201c",
   "metadata": {},
   "source": [
    "##### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5eda1443-a18f-422e-997f-1bf52ca82d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPT = pd.read_csv('/Users/catarinasilva/Desktop/LLM/GPT/repeated_evaluation_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee9d94b7-c49f-438c-aa21-0695ed32ffb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       1400\n",
       "IIB         503\n",
       "ES-SCLC     402\n",
       "IIA         165\n",
       "IVB         145\n",
       "IA          119\n",
       "IIIA        107\n",
       "IV           90\n",
       "IB           68\n",
       "IIIC         59\n",
       "I            54\n",
       "LS-SCLC      53\n",
       "IVA          25\n",
       "II           20\n",
       "III          19\n",
       "IC            9\n",
       "IIC           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb60ad93-ad9d-4997-8478-4ca02545c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_stage\n",
      "<class 'str'>    3240\n",
      "Name: count, dtype: int64\n",
      "predicted_stage\n",
      "<class 'str'>    3240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(GPT[\"true_stage\"].apply(type).value_counts())\n",
    "print(GPT[\"predicted_stage\"].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "530e6fc9-4ec3-45fc-868e-763f43c69751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corrigir\n",
    "GPT_ = correct_predicted_stages(GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66248a55-5576-4933-a365-c2a99400600d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['input_idx', 'run_idx', 'embedding_model', 'retrieval_method',\n",
       "       'llm_model', 'T_stage', 'N_stage', 'M_stage', 'cancer_type',\n",
       "       'true_stage', 'predicted_stage', 'ground_truth_answer',\n",
       "       'predicted_treatment', 'raw_output', 'contexts', 'stage_match',\n",
       "       'RAGAS_faithfulness', 'RAGAS_answer_relevancy',\n",
       "       'RAGAS_context_precision', 'RAGAS_context_recall', 'bertscore_f1',\n",
       "       'bleu', 'rougeL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1318ed4d-92d5-48aa-b5bf-c4ffd0dc999a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       1410\n",
       "IIB         526\n",
       "ES-SCLC     402\n",
       "IVB         197\n",
       "IIA         173\n",
       "IA          135\n",
       "IIIA        115\n",
       "IB           77\n",
       "IIIC         59\n",
       "LS-SCLC      53\n",
       "IVA          47\n",
       "IC           24\n",
       "IV           12\n",
       "IVC           4\n",
       "I             3\n",
       "IIC           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe0dc0e5-dfdb-482a-9b93-45b576b6da29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPT2 = pd.read_csv('/Users/catarinasilva/Desktop/LLM/GPT/repeated_evaluation_results_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d752c24-a42d-4de2-be13-6d9e44111661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       1410\n",
       "IIB         521\n",
       "ES-SCLC     398\n",
       "IVB         194\n",
       "IIA         174\n",
       "IA          134\n",
       "IIIA        113\n",
       "IB           78\n",
       "IIIC         60\n",
       "LS-SCLC      52\n",
       "IVA          49\n",
       "IC           22\n",
       "IV           16\n",
       "I             9\n",
       "IVC           4\n",
       "II            2\n",
       "IIC           2\n",
       "III           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT2['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a74ee407-ceb4-4aec-b179-1bb8adc802d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPT_.to_csv('/Users/catarinasilva/Desktop/GPT_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bddabc8-aecd-44d8-9a90-7ce581cae5b5",
   "metadata": {},
   "source": [
    "##### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518be666-5c36-46b3-b0ff-201b6b2329ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Gemnini = pd.read_csv('/Users/catarinasilva/Desktop/LLM/Gemini/repeated_evaluation_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e0c4e8-4e5a-4d04-9070-16072f1f4572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "III        879\n",
       "ES-SCLC    384\n",
       "IIA        337\n",
       "IIIB       272\n",
       "IIIA       258\n",
       "NaN        182\n",
       "IB         165\n",
       "IIIC       137\n",
       "IIB        134\n",
       "IV         122\n",
       "LS-SCLC     91\n",
       "IVB         91\n",
       "IA          63\n",
       "IVA         53\n",
       "I           34\n",
       "II          21\n",
       "IVC         17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gemnini['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b021cd2-a3ae-4cb9-847a-cc14674fd8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_stage\n",
      "<class 'str'>    3240\n",
      "Name: count, dtype: int64\n",
      "predicted_stage\n",
      "<class 'str'>      3058\n",
      "<class 'float'>     182\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Gemnini[\"true_stage\"].apply(type).value_counts())\n",
    "print(Gemnini[\"predicted_stage\"].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a44e4e28-a86a-4051-8e00-9527ed776e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corrigir\n",
    "Gemnini_ = correct_predicted_stages(Gemnini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4024dcaf-45f8-46de-8558-decef97ea2af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['input_idx', 'run_idx', 'embedding_model', 'retrieval_method',\n",
       "       'llm_model', 'T_stage', 'N_stage', 'M_stage', 'cancer_type',\n",
       "       'true_stage', 'predicted_stage', 'ground_truth_answer',\n",
       "       'predicted_treatment', 'raw_output', 'contexts', 'stage_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gemnini_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f48a5cc6-7016-4f6b-9438-d74682914375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       801\n",
       "IIIA       436\n",
       "ES-SCLC    384\n",
       "IIA        345\n",
       "IIIC       319\n",
       "IA         262\n",
       "IB         174\n",
       "IVB        165\n",
       "IIB        152\n",
       "LS-SCLC     91\n",
       "IVA         72\n",
       "IVC         38\n",
       "I            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gemnini_['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3212f076-8d73-4cf5-800c-2e67ee9f08dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Gemnini2 = pd.read_csv('/Users/catarinasilva/Desktop/LLM/Gemini/repeated_evaluation_results_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca9387b-c5f6-4c31-8d13-44eab420eb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       800\n",
       "IIIA       447\n",
       "ES-SCLC    375\n",
       "IIA        347\n",
       "IIIC       320\n",
       "IA         266\n",
       "IB         168\n",
       "IIB        154\n",
       "IVB        148\n",
       "LS-SCLC     75\n",
       "IVA         72\n",
       "IV          29\n",
       "IVC         29\n",
       "III          9\n",
       "V            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gemnini2['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "906a43ed-1d5b-450c-8624-a492d9117879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Gemnini_.to_csv('/Users/catarinasilva/Desktop/Gemini_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5058b-29f9-474d-9338-5eb3e4f165b6",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45e7ee1-0038-4264-b9b4-b553964a9086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rate limit control\n",
    "REQUEST_TIMESTAMPS = deque()\n",
    "TOKENS_USED = 0\n",
    "MAX_REQUESTS_PER_MINUTE = 3500\n",
    "MAX_TOKENS_PER_MINUTE = 90000\n",
    "\n",
    "def enforce_rate_limits(token_count, llm_model):\n",
    "    \"\"\"Enforce rate limits dynamically for GPT models only.\"\"\"\n",
    "    global REQUEST_TIMESTAMPS, TOKENS_USED\n",
    "    current_time = time.time()\n",
    "\n",
    "    if \"gemini\" in llm_model.lower():\n",
    "        # Gemini: do not apply rate limit logic here, let exception handling manage it\n",
    "        return\n",
    "\n",
    "    # GPT-style rate limiting\n",
    "    while REQUEST_TIMESTAMPS and (current_time - REQUEST_TIMESTAMPS[0]) > 60:\n",
    "        REQUEST_TIMESTAMPS.popleft()\n",
    "\n",
    "    requests_remaining = MAX_REQUESTS_PER_MINUTE - len(REQUEST_TIMESTAMPS)\n",
    "    tokens_remaining = MAX_TOKENS_PER_MINUTE - TOKENS_USED\n",
    "\n",
    "    if requests_remaining <= 0 or tokens_remaining < token_count:\n",
    "        if REQUEST_TIMESTAMPS:\n",
    "            sleep_time = max(1, 60 - (current_time - REQUEST_TIMESTAMPS[0]))\n",
    "        else:\n",
    "            sleep_time = 60\n",
    "        print(f\"Rate limit reached. Sleeping for {sleep_time:.2f} seconds.\")\n",
    "        time.sleep(sleep_time)\n",
    "        TOKENS_USED = 0\n",
    "\n",
    "    REQUEST_TIMESTAMPS.append(current_time)\n",
    "    TOKENS_USED += token_count\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "from bert_score import score as bert_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_bertscore_in_batches(preds, refs, batch_size=100, lang=\"en\"):\n",
    "    f1_all = []\n",
    "    for i in tqdm(range(0, len(preds), batch_size), desc=\"BERTScore batches\"):\n",
    "        batch_preds = preds[i:i+batch_size]\n",
    "        batch_refs = refs[i:i+batch_size]\n",
    "        try:\n",
    "            _, _, f1 = bert_score(batch_preds, batch_refs, lang=lang, verbose=False)\n",
    "            f1_all.extend(f1.cpu().numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"[âŒ BERTScore Error at batch {i}] {e}\")\n",
    "            f1_all.extend([np.nan] * len(batch_preds))  # fallback in case of failure\n",
    "    return f1_all\n",
    "\n",
    "def compute_ragas_safe(dataset):\n",
    "    try:\n",
    "        return evaluate(\n",
    "            dataset,\n",
    "            metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "            llm=llm,\n",
    "            embeddings=embeddings\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[âŒ RAGAS error] {e}\")\n",
    "        return {\"faithfulness\": [np.nan], \"answer_relevancy\": [np.nan],\n",
    "                \"context_precision\": [np.nan], \"context_recall\": [np.nan]}\n",
    "\n",
    "\n",
    "\n",
    "def find_ground_truth(test_set, t_stage, n_stage, m_stage, age, cancer_type):\n",
    "    \"\"\"\n",
    "    Finds the ground truth stage and treatment for the given patient based on NSCLC or SCLC rules.\n",
    "    \"\"\"\n",
    "    if \"SMALL CELL\" in cancer_type.upper():\n",
    "        for _, row in test_set[test_set[\"Cancer Type\"].str.upper().str.contains(\"SMALL CELL\")].iterrows():\n",
    "            t_vals = [v.strip() for v in row[\"T-Stage\"].split(\";\")]\n",
    "            n_vals = [v.strip() for v in row[\"N-Stage\"].split(\";\")]\n",
    "            m_vals = [v.strip() for v in row[\"M-Stage\"].split(\";\")]\n",
    "            age_label = row[\"Age\"].strip()\n",
    "\n",
    "            t_match = \"Any T\" in t_vals or t_stage in t_vals\n",
    "            n_match = \"Any N\" in n_vals or n_stage in n_vals\n",
    "            m_match = \"Any M\" in m_vals or m_stage in m_vals\n",
    "\n",
    "            age_group = \">= 70\" if age >= 70 else \"< 70\"\n",
    "\n",
    "            if t_match and n_match and m_match and age_group == age_label:\n",
    "                return row[\"Stage\"], row[\"Treatment Plan\"]\n",
    "    else:\n",
    "        match = test_set[\n",
    "            (test_set[\"T-Stage\"] == t_stage) &\n",
    "            (test_set[\"N-Stage\"] == n_stage) &\n",
    "            (test_set[\"M-Stage\"] == m_stage)\n",
    "        ]\n",
    "\n",
    "        if match.empty and m_stage.startswith(\"M1\"):\n",
    "            match = test_set[\n",
    "                (test_set[\"M-Stage\"].str.startswith(\"M1\")) &\n",
    "                ((test_set[\"T-Stage\"] == \"Any T\") | test_set[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                ((test_set[\"N-Stage\"] == \"Any N\") | test_set[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "            ]\n",
    "\n",
    "        if not match.empty:\n",
    "            return match.iloc[0][\"Stage\"], match.iloc[0][\"Treatment Plan\"]\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def run_custom_evaluation_pipeline(configurations, k_range, temperature_range, n_repeats,\n",
    "                                   output_path):\n",
    "    test_set = load_ground_truth()\n",
    "    patient_inputs = load_patient_inputs()\n",
    "    all_results = []\n",
    "    ragas_records_map = defaultdict(list)\n",
    "\n",
    "    for idx, patient in tqdm(patient_inputs.iterrows(), total=len(patient_inputs), desc=\"Patients\"):\n",
    "        t_stage, n_stage, m_stage = patient[\"T_stage\"], patient[\"N_stage\"], patient[\"M_stage\"]\n",
    "        age, cancer_type, gender, smoker = int(patient[\"age\"]), patient[\"cancer_type\"], patient[\"Gender\"], patient[\"smoking_status\"]\n",
    "        additional_info = f\"Smoker: {'Yes' if smoker else 'No'}\"\n",
    "        true_stage, true_treatment = find_ground_truth(test_set, t_stage, n_stage, m_stage, age, cancer_type)\n",
    "        if not true_stage:\n",
    "            continue\n",
    "\n",
    "        for config in tqdm(configurations, desc=\"Configurations\", leave=False):\n",
    "            for top_k, temperature in itertools.product(k_range, temperature_range):\n",
    "                for run_idx in range(n_repeats):\n",
    "                    max_retries = 2\n",
    "                    retry_delay = 15  # segundos\n",
    "\n",
    "                    success = False\n",
    "                    for attempt in range(max_retries):\n",
    "                        # Rate limit logic before calling the API\n",
    "                        try:\n",
    "                            enforce_rate_limits(6000, config[\"llm_model\"])\n",
    "                            response, retrieved_docs = retrieval_and_response_pipeline(\n",
    "                                query=\"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                                embedding_model=config[\"embedding_model\"],\n",
    "                                retrieval_method=config[\"retrieval_method\"],\n",
    "                                llm_model=config[\"llm_model\"],\n",
    "                                t_stage=t_stage,\n",
    "                                n_stage=n_stage,\n",
    "                                m_stage=m_stage,\n",
    "                                histopath_grade=\"\",\n",
    "                                cancer_type=cancer_type,\n",
    "                                age=age,\n",
    "                                gender=gender,\n",
    "                                additional_info=additional_info,\n",
    "                                top_k=top_k\n",
    "                            )\n",
    "                            if response and not str(response).startswith(\"ERROR\"):\n",
    "                                success = True\n",
    "                                break\n",
    "\n",
    "                        except Exception as e:\n",
    "                            error_message = str(e)\n",
    "                            if \"429\" in error_message and \"gemini\" in config[\"llm_model\"].lower():\n",
    "                                print(\"[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\")\n",
    "                                time.sleep(86410)\n",
    "                            else:\n",
    "                                print(f\"[âŒ Attempt {attempt+1}/{max_retries}] API Error: {e}\")\n",
    "\n",
    "                            print(f\"[â³ Attempt {attempt+1}/{max_retries}] Retrying in {retry_delay} seconds...\")\n",
    "                            time.sleep(retry_delay)\n",
    "\n",
    "                    if not success:\n",
    "                        print(f\"[âš ï¸] Failed to get response after {max_retries} retries. Skipping input_idx={idx}\")\n",
    "                        continue  # Skip this run_idx safely\n",
    "\n",
    "\n",
    "\n",
    "                    pred_stage, pred_treatment = extract_stage_and_treatment(response)\n",
    "                    result = {\n",
    "                        **config, \"top_k\": top_k, \"temperature\": temperature,\n",
    "                        \"input_idx\": idx, \"run_idx\": run_idx,\n",
    "                        \"T_stage\": t_stage, \"N_stage\": n_stage, \"M_stage\": m_stage,\n",
    "                        \"cancer_type\": cancer_type, \"true_stage\": true_stage,\n",
    "                        \"predicted_stage\": pred_stage, \"ground_truth_answer\": true_treatment,\n",
    "                        \"predicted_treatment\": pred_treatment, \"raw_output\": response,\n",
    "                        \"contexts\": retrieved_docs\n",
    "                    }\n",
    "                    all_results.append(result)\n",
    "                    key = (config[\"embedding_model\"], config[\"retrieval_method\"], config[\"llm_model\"])\n",
    "                    ragas_records_map[key].append({\n",
    "                        \"question\": result[\"raw_output\"],\n",
    "                        \"contexts\": result[\"contexts\"],\n",
    "                        \"answer\": result[\"predicted_treatment\"],\n",
    "                        \"ground_truth\": result[\"ground_truth_answer\"]\n",
    "                    })\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df[\"stage_match\"] = results_df[\"true_stage\"] == results_df[\"predicted_stage\"]\n",
    "    \n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"[âœ”] Saved raw results (before metrics) to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94aa908c-a000-4a46-b6d6-f8070f036f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_from_csv_only(input_csv_path, output_path, grouped_output_path,\n",
    "                           metrics_output_path, classification_report_output_path,\n",
    "                           confusion_matrices_csv_path, ragas_output_path):\n",
    "    import pandas as pd\n",
    "    from datasets import Dataset\n",
    "    from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "    from ragas import evaluate\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "    from sklearn.utils.multiclass import unique_labels\n",
    "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "    from rouge_score import rouge_scorer\n",
    "    from collections import defaultdict\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    df[\"stage_match\"] = df[\"true_stage\"] == df[\"predicted_stage\"]\n",
    "\n",
    "    # Compute BERTScore\n",
    "    preds = df[\"raw_output\"].fillna(\"\").tolist()\n",
    "    refs = df[\"ground_truth_answer\"].fillna(\"\").tolist()\n",
    "    f1_scores = compute_bertscore_in_batches(preds, refs)\n",
    "    df[\"bertscore_f1\"] = f1_scores\n",
    "\n",
    "    # Compute BLEU and ROUGE-L\n",
    "    smoother = SmoothingFunction()\n",
    "    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    bleu_scores, rouge_l_scores = [], []\n",
    "\n",
    "    for pred, ref in tqdm(zip(preds, refs), total=len(preds), desc=\"Scoring\"):\n",
    "        bleu = sentence_bleu([ref.split()], pred.split(), smoothing_function=smoother.method1)\n",
    "        rouge_l = rouge.score(ref, pred)[\"rougeL\"].fmeasure\n",
    "        bleu_scores.append(bleu)\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "\n",
    "    df[\"bleu\"] = bleu_scores\n",
    "    df[\"rougeL\"] = rouge_l_scores\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Grouped metrics\n",
    "    grouped = df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\"])[\n",
    "        [\"stage_match\", \"bertscore_f1\", \"bleu\", \"rougeL\"] #, \"top_k\", \"temperature\"\n",
    "    ].agg([\"mean\", \"std\"]).reset_index()\n",
    "    grouped.columns = [\"_\".join(col).strip() if isinstance(col, tuple) else col for col in grouped.columns.values]\n",
    "    grouped.to_csv(grouped_output_path, index=False)\n",
    "\n",
    "    # Confusion matrix and classification report\n",
    "    metrics = []\n",
    "    classification_reports = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    labels = unique_labels(df[\"true_stage\"], df[\"predicted_stage\"])\n",
    "\n",
    "    for name, group in tqdm(df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\"]), desc=\"Metrics\"): #, \"top_k\", \"temperature\"\n",
    "        cm = confusion_matrix(group[\"true_stage\"], group[\"predicted_stage\"], labels=labels)\n",
    "        acc = accuracy_score(group[\"true_stage\"], group[\"predicted_stage\"])\n",
    "        f1 = f1_score(group[\"true_stage\"], group[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "        prec = precision_score(group[\"true_stage\"], group[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "        rec = recall_score(group[\"true_stage\"], group[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "\n",
    "        report = classification_report(group[\"true_stage\"], group[\"predicted_stage\"], output_dict=True, zero_division=0)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        for i, val in zip([\"embedding_model\", \"retrieval_method\", \"llm_model\"], name): #, \"top_k\", \"temperature\"\n",
    "            report_df[i] = val\n",
    "        classification_reports.append(report_df)\n",
    "\n",
    "        metrics.append({\n",
    "            \"embedding_model\": name[0],\n",
    "            \"retrieval_method\": name[1],\n",
    "            \"llm_model\": name[2],\n",
    "            #\"top_k\": name[3],\n",
    "            #\"temperature\": name[4],\n",
    "            \"accuracy\": acc,\n",
    "            \"f1_score\": f1,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"confusion_matrix\": cm.tolist()\n",
    "        })\n",
    "\n",
    "        cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "        cm_df.index.name = 'True_Stage'\n",
    "        cm_df[\"embedding_model\"] = name[0]\n",
    "        cm_df[\"retrieval_method\"] = name[1]\n",
    "        cm_df[\"llm_model\"] = name[2]\n",
    "        #cm_df[\"top_k\"] = name[3]\n",
    "        #cm_df[\"temperature\"] = name[4]\n",
    "        confusion_matrices.append(cm_df)\n",
    "\n",
    "    pd.DataFrame(metrics).to_csv(metrics_output_path, index=False)\n",
    "    pd.concat(classification_reports).reset_index().to_csv(classification_report_output_path, index=False)\n",
    "    pd.concat(confusion_matrices).to_csv(confusion_matrices_csv_path, index=True)\n",
    "\n",
    "    # Compute RAGAS\n",
    "    print(\"\\n[âœ”] Computing RAGAS...\")\n",
    "    ragas_summary = []\n",
    "    grouped = df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\"]) #, \"top_k\", \"temperature\"\n",
    "\n",
    "    for name, group in grouped:\n",
    "        records = []\n",
    "        for _, row in group.iterrows():\n",
    "            records.append({\n",
    "                \"question\": \"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                \"contexts\": eval(row[\"contexts\"]) if isinstance(row[\"contexts\"], str) else row[\"contexts\"],\n",
    "                \"answer\": row[\"raw_output\"],\n",
    "                \"ground_truth\": row[\"ground_truth_answer\"]\n",
    "            })\n",
    "\n",
    "        dataset = Dataset.from_list(records)\n",
    "        ragas_result = compute_ragas_safe(dataset)\n",
    "\n",
    "        ragas_summary.append({\n",
    "            \"embedding_model\": name[0],\n",
    "            \"retrieval_method\": name[1],\n",
    "            \"llm_model\": name[2],\n",
    "            #\"top_k\": name[3],\n",
    "            #\"temperature\": name[4],\n",
    "            \"RAGAS_Faithfulness\": np.nanmean(ragas_result[\"faithfulness\"]),\n",
    "            \"RAGAS_AnswerRelevancy\": np.nanmean(ragas_result[\"answer_relevancy\"]),\n",
    "            \"RAGAS_ContextPrecision\": np.nanmean(ragas_result[\"context_precision\"]),\n",
    "            \"RAGAS_ContextRecall\": np.nanmean(ragas_result[\"context_recall\"])\n",
    "        })\n",
    "\n",
    "    pd.DataFrame(ragas_summary).to_csv(ragas_output_path, index=False)\n",
    "    print(\"[âœ”] Finished evaluation from CSV only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc45f4a-3d52-473e-96a1-f5f270a06632",
   "metadata": {},
   "source": [
    "##### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "656ba1c6-3541-4cf1-97fe-86f05c17cb57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERTScore batches:   0%|                                 | 0/33 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   3%|â–Š                        | 1/33 [01:37<51:59, 97.48s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   6%|â–ˆâ–Œ                       | 2/33 [03:03<46:49, 90.64s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   9%|â–ˆâ–ˆâ–Ž                      | 3/33 [04:34<45:26, 90.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  12%|â–ˆâ–ˆâ–ˆ                      | 4/33 [06:03<43:28, 89.96s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  15%|â–ˆâ–ˆâ–ˆâ–Š                     | 5/33 [07:33<42:03, 90.12s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 6/33 [09:09<41:24, 92.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 7/33 [10:37<39:19, 90.76s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 8/33 [12:06<37:39, 90.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 9/33 [13:35<35:55, 89.83s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 10/33 [15:05<34:30, 90.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 11/33 [16:36<33:03, 90.16s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 12/33 [18:09<31:52, 91.06s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 13/33 [19:42<30:33, 91.67s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 14/33 [21:14<29:00, 91.60s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 15/33 [22:44<27:25, 91.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 16/33 [24:18<26:04, 92.02s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 17/33 [25:52<24:42, 92.63s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 18/33 [27:25<23:11, 92.75s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 19/33 [28:58<21:37, 92.67s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 20/33 [30:24<19:41, 90.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 21/33 [31:46<17:36, 88.04s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 22/33 [33:10<15:55, 86.84s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 23/33 [34:34<14:19, 85.94s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 24/33 [35:58<12:48, 85.41s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/33 [37:24<11:24, 85.59s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 26/33 [38:49<09:57, 85.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/33 [40:14<08:31, 85.26s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 28/33 [41:39<07:06, 85.29s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 29/33 [43:04<05:40, 85.14s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 30/33 [44:33<04:18, 86.27s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/33 [45:37<02:39, 79.71s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 32/33 [46:29<01:11, 71.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [46:50<00:00, 85.17s/it]\n",
      "Scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3240/3240 [01:48<00:00, 29.97it/s]\n",
      "Metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 88.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[âœ”] Computing RAGAS...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18aadc748d74df6aa77a4090478d2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[328]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[452]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[632]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[776]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1059]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1196]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1298]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1311]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c45f36b0c6e41de895c253c693ba7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[50]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[150]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[214]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[242]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[250]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[358]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[650]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1022]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd403cb0770f4b6b96ba8c4c74e30344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[352]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc13c84f01f04a04adfdd4ae944c59a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[431]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[527]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[711]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[991]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[992]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[996]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[999]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1000]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1004]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1046]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c8e49df1654d6ca6d5d4f750ba56a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a199f7fcd841bdbafe9f3692cdb608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[543]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1168]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5663c95ed24dd0bc58f0b38a0dc4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[87]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[392]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[396]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[474]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[544]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[551]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1051]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1056]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1292]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1336]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597346daa1d6425bac557e56ab289da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[303]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[403]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[555]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[556]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[560]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[704]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[944]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[951]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[999]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dd77e443d942ceac2b4f9e07dde450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[676]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1256]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1263]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Finished evaluation from CSV only.\n"
     ]
    }
   ],
   "source": [
    "evaluate_from_csv_only(\n",
    "    input_csv_path = '/Users/catarinasilva/Desktop/GPT_results.csv', \n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_GPT/repeated_evaluation_results.csv\",\n",
    "    grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_GPT/results_summary.csv\",\n",
    "    metrics_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_GPT/metrics_and_confusion_matrix.csv\",\n",
    "    classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_GPT/classification_report.csv\",\n",
    "    confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_GPT/confusion_matrix_report.csv\",\n",
    "    ragas_output_path= \"/Users/catarinasilva/Desktop/LLM/Final_eval_GPT/ragas_summary.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598801c-1887-48b2-9f91-c4b87d1ac1fa",
   "metadata": {},
   "source": [
    "##### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a71143-9595-4b2f-8933-c22533d6ea74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERTScore batches:   0%|                                 | 0/33 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   3%|â–Š                        | 1/33 [00:48<25:41, 48.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   6%|â–ˆâ–Œ                       | 2/33 [01:34<24:17, 47.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   9%|â–ˆâ–ˆâ–Ž                      | 3/33 [02:21<23:36, 47.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  12%|â–ˆâ–ˆâ–ˆ                      | 4/33 [03:08<22:44, 47.05s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  15%|â–ˆâ–ˆâ–ˆâ–Š                     | 5/33 [03:59<22:40, 48.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 6/33 [04:48<21:51, 48.56s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 7/33 [05:36<21:01, 48.52s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 8/33 [06:26<20:19, 48.78s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 9/33 [07:14<19:28, 48.70s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 10/33 [08:03<18:38, 48.63s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 11/33 [08:51<17:47, 48.55s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 12/33 [09:42<17:16, 49.33s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 13/33 [10:31<16:24, 49.21s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 14/33 [11:23<15:49, 49.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 15/33 [12:13<15:02, 50.16s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 16/33 [13:02<14:03, 49.62s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 17/33 [13:50<13:08, 49.28s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 18/33 [14:42<12:28, 49.93s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 19/33 [15:32<11:41, 50.13s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 20/33 [16:21<10:45, 49.69s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 21/33 [17:10<09:54, 49.54s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 22/33 [18:00<09:04, 49.50s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 23/33 [18:49<08:15, 49.54s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 24/33 [19:39<07:27, 49.73s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/33 [20:29<06:38, 49.80s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 26/33 [21:21<05:52, 50.29s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/33 [22:11<05:01, 50.29s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 28/33 [23:01<04:11, 50.32s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 29/33 [23:51<03:20, 50.19s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 30/33 [24:41<02:29, 49.87s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/33 [25:30<01:39, 49.74s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 32/33 [26:20<00:49, 49.76s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [26:40<00:00, 48.50s/it]\n",
      "Scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3240/3240 [01:33<00:00, 34.67it/s]\n",
      "Metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 99.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[âœ”] Computing RAGAS...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbe11708ea9403a9da93b6680d253d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[140]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[368]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[380]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[679]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[744]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1064]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1078]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1140]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1203]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1306]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7789c7eea84105a6067550277a6274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[39]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[84]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[260]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[290]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[607]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[608]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[675]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[679]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[874]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[970]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1311]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1336]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1399]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7e40c889aa45b8b01ce9767b1ef86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[384]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[607]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[615]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[791]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[816]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[832]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1176]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1306]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19a57cc74764d87a082e4cd7c4d7dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[84]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[527]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[535]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[540]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[628]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[751]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[844]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1340]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d61b2a7a0844fee8f289da3fee83f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[248]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[276]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a871846bbff447cb119896707eee40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[496]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[624]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[980]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1252]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a68b47742047f5ac967e5d7056c699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[39]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[72]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[80]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[88]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[236]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[239]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[312]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[315]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[327]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[359]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[392]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[520]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[536]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[548]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[551]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[616]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[636]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[703]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[766]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[884]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[936]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1228]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1259]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1263]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1295]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1323]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1367]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1403]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb42e74f4e0c4f9ea87db023de8378a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[256]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[263]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[268]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[319]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[495]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[496]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[575]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[734]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[974]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1334]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39160b5771c842ecb49051c32c63f58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[139]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[956]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1076]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[1380]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Finished evaluation from CSV only.\n"
     ]
    }
   ],
   "source": [
    "evaluate_from_csv_only(\n",
    "    input_csv_path = \"/Users/catarinasilva/Desktop/Gemini_results.csv\", \n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_Gemini/repeated_evaluation_results.csv\",\n",
    "    grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_Gemini/results_summary.csv\",\n",
    "    metrics_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_Gemini/metrics_and_confusion_matrix.csv\",\n",
    "    classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_Gemini/classification_report.csv\",\n",
    "    confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval_Gemini/confusion_matrix_report.csv\",\n",
    "    ragas_output_path= \"/Users/catarinasilva/Desktop/LLM/Final_eval_Gemini/ragas_summary.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd96171-82cd-46c3-9b16-2b4b10db4db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733cb46e-691a-4cfa-81b2-83550ad0c499",
   "metadata": {},
   "source": [
    "### Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "514b1722-e77a-459e-bd5a-538eee1c0109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rate limit control\n",
    "REQUEST_TIMESTAMPS = deque()\n",
    "TOKENS_USED = 0\n",
    "MAX_REQUESTS_PER_MINUTE = 3500\n",
    "MAX_TOKENS_PER_MINUTE = 90000\n",
    "\n",
    "def enforce_rate_limits(token_count, llm_model):\n",
    "    \"\"\"Enforce rate limits dynamically for GPT models only.\"\"\"\n",
    "    global REQUEST_TIMESTAMPS, TOKENS_USED\n",
    "    current_time = time.time()\n",
    "\n",
    "    if \"gemini\" in llm_model.lower():\n",
    "        # Gemini: do not apply rate limit logic here, let exception handling manage it\n",
    "        return\n",
    "\n",
    "    # GPT-style rate limiting\n",
    "    while REQUEST_TIMESTAMPS and (current_time - REQUEST_TIMESTAMPS[0]) > 60:\n",
    "        REQUEST_TIMESTAMPS.popleft()\n",
    "\n",
    "    requests_remaining = MAX_REQUESTS_PER_MINUTE - len(REQUEST_TIMESTAMPS)\n",
    "    tokens_remaining = MAX_TOKENS_PER_MINUTE - TOKENS_USED\n",
    "\n",
    "    if requests_remaining <= 0 or tokens_remaining < token_count:\n",
    "        if REQUEST_TIMESTAMPS:\n",
    "            sleep_time = max(1, 60 - (current_time - REQUEST_TIMESTAMPS[0]))\n",
    "        else:\n",
    "            sleep_time = 60\n",
    "        print(f\"Rate limit reached. Sleeping for {sleep_time:.2f} seconds.\")\n",
    "        time.sleep(sleep_time)\n",
    "        TOKENS_USED = 0\n",
    "\n",
    "    REQUEST_TIMESTAMPS.append(current_time)\n",
    "    TOKENS_USED += token_count\n",
    "\n",
    "from bert_score import score as bert_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_bertscore_in_batches(preds, refs, batch_size=100, lang=\"en\"):\n",
    "    f1_all = []\n",
    "    for i in tqdm(range(0, len(preds), batch_size), desc=\"BERTScore batches\"):\n",
    "        batch_preds = preds[i:i+batch_size]\n",
    "        batch_refs = refs[i:i+batch_size]\n",
    "        try:\n",
    "            _, _, f1 = bert_score(batch_preds, batch_refs, lang=lang, verbose=False)\n",
    "            f1_all.extend(f1.cpu().numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"[âŒ BERTScore Error at batch {i}] {e}\")\n",
    "            f1_all.extend([np.nan] * len(batch_preds))  # fallback in case of failure\n",
    "    return f1_all\n",
    "\n",
    "def compute_ragas_safe(dataset):\n",
    "    try:\n",
    "        return evaluate(\n",
    "            dataset,\n",
    "            metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "            llm=llm,\n",
    "            embeddings=embeddings\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[âŒ RAGAS error] {e}\")\n",
    "        return {\"faithfulness\": [np.nan], \"answer_relevancy\": [np.nan],\n",
    "                \"context_precision\": [np.nan], \"context_recall\": [np.nan]}\n",
    "\n",
    "\n",
    "\n",
    "def find_ground_truth(test_set, t_stage, n_stage, m_stage, age, cancer_type):\n",
    "    \"\"\"\n",
    "    Finds the ground truth stage and treatment for the given patient based on NSCLC or SCLC rules.\n",
    "    \"\"\"\n",
    "    if \"SMALL CELL\" in cancer_type.upper():\n",
    "        for _, row in test_set[test_set[\"Cancer Type\"].str.upper().str.contains(\"SMALL CELL\")].iterrows():\n",
    "            t_vals = [v.strip() for v in row[\"T-Stage\"].split(\";\")]\n",
    "            n_vals = [v.strip() for v in row[\"N-Stage\"].split(\";\")]\n",
    "            m_vals = [v.strip() for v in row[\"M-Stage\"].split(\";\")]\n",
    "            age_label = row[\"Age\"].strip()\n",
    "\n",
    "            t_match = \"Any T\" in t_vals or t_stage in t_vals\n",
    "            n_match = \"Any N\" in n_vals or n_stage in n_vals\n",
    "            m_match = \"Any M\" in m_vals or m_stage in m_vals\n",
    "\n",
    "            age_group = \">= 70\" if age >= 70 else \"< 70\"\n",
    "\n",
    "            if t_match and n_match and m_match and age_group == age_label:\n",
    "                return row[\"Stage\"], row[\"Treatment Plan\"]\n",
    "    else:\n",
    "        match = test_set[\n",
    "            (test_set[\"T-Stage\"] == t_stage) &\n",
    "            (test_set[\"N-Stage\"] == n_stage) &\n",
    "            (test_set[\"M-Stage\"] == m_stage)\n",
    "        ]\n",
    "\n",
    "        if match.empty and m_stage.startswith(\"M1\"):\n",
    "            match = test_set[\n",
    "                (test_set[\"M-Stage\"].str.startswith(\"M1\")) &\n",
    "                ((test_set[\"T-Stage\"] == \"Any T\") | test_set[\"T-Stage\"].str.contains(\"Any\", case=False)) &\n",
    "                ((test_set[\"N-Stage\"] == \"Any N\") | test_set[\"N-Stage\"].str.contains(\"Any\", case=False))\n",
    "            ]\n",
    "\n",
    "        if not match.empty:\n",
    "            return match.iloc[0][\"Stage\"], match.iloc[0][\"Treatment Plan\"]\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def run_custom_evaluation_pipeline(configurations, k_range, temperature_range, n_repeats,\n",
    "                                   output_path):\n",
    "    test_set = load_ground_truth()\n",
    "    patient_inputs = load_patient_inputs()\n",
    "    all_results = []\n",
    "    ragas_records_map = defaultdict(list)\n",
    "\n",
    "    for idx, patient in tqdm(patient_inputs.iterrows(), total=len(patient_inputs), desc=\"Patients\"):\n",
    "        t_stage, n_stage, m_stage = patient[\"T_stage\"], patient[\"N_stage\"], patient[\"M_stage\"]\n",
    "        age, cancer_type, gender, smoker = int(patient[\"age\"]), patient[\"cancer_type\"], patient[\"Gender\"], patient[\"smoking_status\"]\n",
    "        additional_info = f\"Smoker: {'Yes' if smoker else 'No'}\"\n",
    "        true_stage, true_treatment = find_ground_truth(test_set, t_stage, n_stage, m_stage, age, cancer_type)\n",
    "        if not true_stage:\n",
    "            continue\n",
    "\n",
    "        for config in tqdm(configurations, desc=\"Configurations\", leave=False):\n",
    "            for top_k, temperature in itertools.product(k_range, temperature_range):\n",
    "                for run_idx in range(n_repeats):\n",
    "                    max_retries = 2\n",
    "                    retry_delay = 15  # segundos\n",
    "\n",
    "                    success = False\n",
    "                    for attempt in range(max_retries):\n",
    "                        # Rate limit logic before calling the API\n",
    "                        try:\n",
    "                            enforce_rate_limits(6000, config[\"llm_model\"])\n",
    "                            response, retrieved_docs = retrieval_and_response_pipeline(\n",
    "                                query=\"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                                embedding_model=config[\"embedding_model\"],\n",
    "                                retrieval_method=config[\"retrieval_method\"],\n",
    "                                llm_model=config[\"llm_model\"],\n",
    "                                t_stage=t_stage,\n",
    "                                n_stage=n_stage,\n",
    "                                m_stage=m_stage,\n",
    "                                histopath_grade=\"\",\n",
    "                                cancer_type=cancer_type,\n",
    "                                age=age,\n",
    "                                gender=gender,\n",
    "                                additional_info=additional_info,\n",
    "                                top_k=top_k\n",
    "                            )\n",
    "                            if response and not str(response).startswith(\"ERROR\"):\n",
    "                                success = True\n",
    "                                break\n",
    "\n",
    "                        except Exception as e:\n",
    "                            error_message = str(e)\n",
    "                            if \"429\" in error_message and \"gemini\" in config[\"llm_model\"].lower():\n",
    "                                print(\"[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\")\n",
    "                                time.sleep(86410)\n",
    "                            else:\n",
    "                                print(f\"[âŒ Attempt {attempt+1}/{max_retries}] API Error: {e}\")\n",
    "\n",
    "                            print(f\"[â³ Attempt {attempt+1}/{max_retries}] Retrying in {retry_delay} seconds...\")\n",
    "                            time.sleep(retry_delay)\n",
    "\n",
    "                    if not success:\n",
    "                        print(f\"[âš ï¸] Failed to get response after {max_retries} retries. Skipping input_idx={idx}\")\n",
    "                        continue  # Skip this run_idx safely\n",
    "\n",
    "\n",
    "\n",
    "                    pred_stage, pred_treatment = extract_stage_and_treatment(response)\n",
    "                    result = {\n",
    "                        **config, \"top_k\": top_k, \"temperature\": temperature,\n",
    "                        \"input_idx\": idx, \"run_idx\": run_idx,\n",
    "                        \"T_stage\": t_stage, \"N_stage\": n_stage, \"M_stage\": m_stage,\n",
    "                        \"cancer_type\": cancer_type, \"true_stage\": true_stage,\n",
    "                        \"predicted_stage\": pred_stage, \"ground_truth_answer\": true_treatment,\n",
    "                        \"predicted_treatment\": pred_treatment, \"raw_output\": response,\n",
    "                        \"contexts\": retrieved_docs\n",
    "                    }\n",
    "                    all_results.append(result)\n",
    "                    key = (config[\"embedding_model\"], config[\"retrieval_method\"], config[\"llm_model\"])\n",
    "                    ragas_records_map[key].append({\n",
    "                        \"question\": result[\"raw_output\"],\n",
    "                        \"contexts\": result[\"contexts\"],\n",
    "                        \"answer\": result[\"predicted_treatment\"],\n",
    "                        \"ground_truth\": result[\"ground_truth_answer\"]\n",
    "                    })\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df[\"stage_match\"] = results_df[\"true_stage\"] == results_df[\"predicted_stage\"]\n",
    "    \n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"[âœ”] Saved raw results (before metrics) to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c4213c-e14f-42f9-ba83-386e8a735966",
   "metadata": {},
   "source": [
    "#### GeminiCombinedGemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffee6d66-f835-4e3d-924c-d3516c719f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs_1 = [\n",
    "    {\n",
    "        \"embedding_model\": \"gemini\",\n",
    "        \"retrieval_method\": \"combined\",\n",
    "        \"llm_model\": \"gemini\"\n",
    "    }\n",
    " \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f95f6e9-2827-47d4-86d1-008ca5110ea8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patients:   0%|                                          | 0/36 [00:00<?, ?it/s]\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:15<00:00, 735.33s/it]\u001b[A\n",
      "Patients:   3%|â–Š                              | 1/36 [12:15<7:08:56, 735.34s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:09<00:00, 909.33s/it]\u001b[A\n",
      "Patients:   6%|â–ˆâ–‹                             | 2/36 [27:24<7:54:41, 837.70s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:53<00:00, 893.38s/it]\u001b[A\n",
      "Patients:   8%|â–ˆâ–ˆâ–Œ                            | 3/36 [42:18<7:54:43, 863.14s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:58<00:00, 778.24s/it]\u001b[A\n",
      "Patients:  11%|â–ˆâ–ˆâ–ˆâ–                           | 4/36 [55:16<7:22:28, 829.63s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:08<00:00, 908.37s/it]\u001b[A\n",
      "Patients:  14%|â–ˆâ–ˆâ–ˆâ–ˆ                         | 5/36 [1:10:24<7:23:19, 858.04s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:37<00:00, 817.53s/it]\u001b[A\n",
      "Patients:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 6/36 [1:24:02<7:02:08, 844.28s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:14:53<00:00, 87293.06s/it]\u001b[A\n",
      "Patients:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 7/36 [25:38:55<234:28:06, 29106.43s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:13<00:00, 1453.91s/it]\u001b[A\n",
      "Patients:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 8/36 [26:03:09<157:54:49, 20303.20s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [22:19<00:00, 1339.39s/it]\u001b[A\n",
      "Patients:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 9/36 [26:25:28<107:48:40, 14374.84s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:39<00:00, 999.36s/it]\u001b[A\n",
      "Patients:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 10/36 [26:42:08<73:59:44, 10245.56s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:54<00:00, 954.26s/it]\u001b[A\n",
      "Patients:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 11/36 [26:58:02<51:24:08, 7401.95s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:25:31<00:00, 87931.53s/it]\u001b[A\n",
      "Patients:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 12/36 [51:23:34<212:39:57, 31899.91s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:55<00:00, 1075.31s/it]\u001b[A\n",
      "Patients:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 13/36 [51:41:29<144:08:47, 22562.07s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [20:58<00:00, 1258.77s/it]\u001b[A\n",
      "Patients:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 14/36 [52:02:28<98:33:23, 16127.45s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [19:14<00:00, 1154.22s/it]\u001b[A\n",
      "Patients:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 15/36 [52:21:42<67:44:55, 11614.06s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:22<00:00, 1102.62s/it]\u001b[A\n",
      "Patients:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 16/36 [52:40:05<46:56:42, 8450.13s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [19:39<00:00, 1179.88s/it]\u001b[A\n",
      "Patients:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 17/36 [52:59:44<33:03:35, 6263.97s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:18:09<00:00, 87489.33s/it]\u001b[A\n",
      "Patients:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 18/36 [77:17:54<153:21:23, 30671.33s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [19:51<00:00, 1191.03s/it]\u001b[A\n",
      "Patients:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 19/36 [77:37:45<103:01:31, 21817.16s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:44<00:00, 1064.90s/it]\u001b[A\n",
      "Patients:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 20/36 [77:55:30<69:16:24, 15586.52s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:31<00:00, 1111.06s/it]\u001b[A\n",
      "Patients:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 21/36 [78:14:01<46:50:21, 11241.47s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:49<00:00, 1069.56s/it]\u001b[A\n",
      "Patients:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 22/36 [78:31:51<31:50:41, 8188.71s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:14<00:00, 1034.06s/it]\u001b[A\n",
      "Patients:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 23/36 [78:49:05<21:49:02, 6041.74s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:19:39<00:00, 87579.59s/it]\u001b[A\n",
      "Patients:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 24/36 [103:08:44<101:41:33, 30507.79s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:46<00:00, 1066.48s/it]\u001b[A\n",
      "Patients:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 25/36 [103:26:31<66:13:36, 21674.22s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [19:06<00:00, 1146.80s/it]\u001b[A\n",
      "Patients:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 26/36 [103:45:38<43:05:54, 15515.42s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:34<00:00, 1114.73s/it]\u001b[A\n",
      "Patients:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 27/36 [104:04:12<27:59:14, 11194.94s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:14<00:00, 1094.33s/it]\u001b[A\n",
      "Patients:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 28/36 [104:22:27<18:08:36, 8164.62s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [19:22<00:00, 1162.08s/it]\u001b[A\n",
      "Patients:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 29/36 [104:41:49<11:47:26, 6063.80s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:19:32<00:00, 87572.82s/it]\u001b[A\n",
      "Patients:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30/36 [129:01:22<50:51:42, 30517.07s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:56<00:00, 1076.07s/it]\u001b[A\n",
      "Patients:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 31/36 [129:19:18<30:07:03, 21684.64s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:06<00:00, 846.32s/it]\u001b[A\n",
      "Patients:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 32/36 [129:33:24<17:08:52, 15433.08s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:28<00:00, 868.09s/it]\u001b[A\n",
      "Patients:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 33/36 [129:47:52<9:13:10, 11063.56s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:04<00:00, 784.85s/it]\u001b[A\n",
      "Patients:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/36 [130:00:57<4:25:59, 7979.94s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:39<00:00, 819.67s/it]\u001b[A\n",
      "Patients:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 35/36 [130:14:37<1:37:11, 5831.86s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:16<00:00, 796.64s/it]\u001b[A\n",
      "Patients: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [130:27:53<00:00, 13046.50s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Saved raw results (before metrics) to /Users/catarinasilva/Desktop/LLM/Final_eval/repeated_evaluation_results_GeminiCombinedGemini.csv\n",
      "CPU times: user 16min 54s, sys: 4min 19s, total: 21min 13s\n",
      "Wall time: 5d 10h 27min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k_range = [5, 7, 10, 15]\n",
    "temperature_range = [0, 0.3, 0.5, 0.7]\n",
    "n_repeats = 10\n",
    "\n",
    "GROUND_TRUTH_PATH = \"/Users/catarinasilva/Desktop/Lung_Cancer_Treatment_Stages_Final.csv\"\n",
    "INPUT_PATIENTS_PATH = \"/Users/catarinasilva/Desktop/patient_inputs_sample.csv\"\n",
    "\n",
    "run_custom_evaluation_pipeline(\n",
    "    configurations=configs_1,\n",
    "    k_range=k_range,\n",
    "    temperature_range=temperature_range,\n",
    "    n_repeats=n_repeats,\n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/repeated_evaluation_results_GeminiCombinedGemini.csv\",\n",
    "    #grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/results_summary_GeminiCombinedGemini.csv\",\n",
    "    #metrics_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/metrics_and_confusion_matrix.csv\",\n",
    "    #classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/classification_report.csv\",\n",
    "    #confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/confusion_matrix_report.csv\",\n",
    "    #ragas_output= \"/Users/catarinasilva/Desktop/LLM/Final_eval/ragas_summary.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dcaf2b-fd6b-4d1e-8c7e-20156fea603b",
   "metadata": {},
   "source": [
    "#### MiniLMCombinedGemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a000cb84-94ce-4808-85cd-1219fde23d98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs_2 = [\n",
    "    {\n",
    "        \"embedding_model\": \"openai\",\n",
    "        \"retrieval_method\": \"combined\",\n",
    "        \"llm_model\": \"gemini\"\n",
    "    }\n",
    " \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ce1cc3f-3963-47b7-ad81-9755b1ccbb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patients:   0%|                                          | 0/36 [00:00<?, ?it/s]\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:08<00:00, 728.51s/it]\u001b[A\n",
      "Patients:   3%|â–Š                              | 1/36 [12:08<7:04:58, 728.52s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:51<00:00, 831.70s/it]\u001b[A\n",
      "Patients:   6%|â–ˆâ–‹                             | 2/36 [26:00<7:27:13, 789.22s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:07<00:00, 727.64s/it]\u001b[A\n",
      "Patients:   8%|â–ˆâ–ˆâ–Œ                            | 3/36 [38:07<6:58:36, 761.12s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:14:10<00:00, 87250.67s/it]\u001b[A\n",
      "Patients:  11%|â–ˆâ–ˆâ–‹                     | 4/36 [24:52:18<310:16:39, 34906.23s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:23<00:00, 863.50s/it]\u001b[A\n",
      "Patients:  14%|â–ˆâ–ˆâ–ˆâ–Ž                    | 5/36 [25:06:42<194:52:15, 22630.19s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:33<00:00, 873.36s/it]\u001b[A\n",
      "Patients:  17%|â–ˆâ–ˆâ–ˆâ–ˆ                    | 6/36 [25:21:15<126:56:25, 15232.87s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:21<00:00, 861.05s/it]\u001b[A\n",
      "Patients:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 7/36 [25:35:36<84:51:37, 10534.39s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:11<00:00, 851.01s/it]\u001b[A\n",
      "Patients:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 8/36 [25:49:47<57:57:27, 7451.68s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:39<00:00, 879.40s/it]\u001b[A\n",
      "Patients:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 9/36 [26:04:27<40:28:41, 5397.10s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:16:57<00:00, 87417.00s/it]\u001b[A\n",
      "Patients:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 10/36 [50:21:24<221:51:16, 30718.35s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:17<00:00, 977.57s/it]\u001b[A\n",
      "Patients:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 11/36 [50:37:41<150:06:43, 21616.14s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:19<00:00, 1039.27s/it]\u001b[A\n",
      "Patients:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 12/36 [50:55:01<102:22:34, 15356.44s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:05<00:00, 1025.68s/it]\u001b[A\n",
      "Patients:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 13/36 [51:12:06<70:22:28, 11015.15s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:44<00:00, 1004.91s/it]\u001b[A\n",
      "Patients:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 14/36 [51:28:51<48:50:14, 7991.58s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:41<00:00, 1061.11s/it]\u001b[A\n",
      "Patients:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 15/36 [51:46:32<34:25:53, 5902.53s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:10<00:00, 1030.75s/it]\u001b[A\n",
      "Patients:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 16/36 [52:03:43<24:38:42, 4436.13s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:15:42<00:00, 87342.76s/it]\u001b[A\n",
      "Patients:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 17/36 [76:19:26<154:59:16, 29366.12s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:18<00:00, 978.70s/it]\u001b[A\n",
      "Patients:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 18/36 [76:35:45<104:10:48, 20836.01s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:54<00:00, 894.38s/it]\u001b[A\n",
      "Patients:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 19/36 [76:50:39<70:06:33, 14846.70s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:02<00:00, 1022.64s/it]\u001b[A\n",
      "Patients:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 20/36 [77:07:42<47:32:18, 10696.18s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:18<00:00, 1098.34s/it]\u001b[A\n",
      "Patients:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 21/36 [77:26:00<32:33:48, 7815.22s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:22<00:00, 922.10s/it]\u001b[A\n",
      "Patients:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 22/36 [77:41:22<22:20:50, 5746.48s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:18:22<00:00, 87502.37s/it]\u001b[A\n",
      "Patients:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 23/36 [101:59:45<109:20:39, 30279.97s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:22<00:00, 1042.54s/it]\u001b[A\n",
      "Patients:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 24/36 [102:17:07<71:41:24, 21507.07s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:35<00:00, 995.78s/it]\u001b[A\n",
      "Patients:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 25/36 [102:33:43<46:54:41, 15352.87s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:10<00:00, 1030.91s/it]\u001b[A\n",
      "Patients:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 26/36 [102:50:54<30:42:38, 11055.89s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:41<00:00, 1061.42s/it]\u001b[A\n",
      "Patients:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 27/36 [103:08:35<20:08:36, 8057.36s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:25<00:00, 985.33s/it]\u001b[A\n",
      "Patients:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 28/36 [103:25:01<13:11:25, 5935.66s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [20:58<00:00, 1258.51s/it]\u001b[A\n",
      "Patients:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/36 [103:45:59<8:48:47, 4532.48s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [19:58<00:00, 1198.48s/it]\u001b[A\n",
      "Patients:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 30/36 [104:05:58<5:53:13, 3532.27s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:20<00:00, 1100.37s/it]\u001b[A\n",
      "Patients:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31/36 [104:24:18<3:53:33, 2802.70s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:54<00:00, 834.70s/it]\u001b[A\n",
      "Patients:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 32/36 [104:38:13<2:27:29, 2212.30s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:13<00:00, 913.50s/it]\u001b[A\n",
      "Patients:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 33/36 [104:53:26<1:31:08, 1822.67s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:20<00:00, 860.43s/it]\u001b[A\n",
      "Patients:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/36 [105:07:47<51:08, 1534.00s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:14:18<00:00, 87258.27s/it]\u001b[A\n",
      "Patients:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 35/36 [129:22:05<7:34:11, 27251.39s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:20<00:00, 920.54s/it]\u001b[A\n",
      "Patients: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [129:37:26<00:00, 12962.40s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Saved raw results (before metrics) to /Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/repeated_evaluation_results_OpenAICombinedGemini.csv\n",
      "CPU times: user 16min 47s, sys: 4min 26s, total: 21min 14s\n",
      "Wall time: 5d 9h 37min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k_range = [5, 7, 10, 15]\n",
    "temperature_range = [0, 0.3, 0.5, 0.7]\n",
    "n_repeats = 10\n",
    "\n",
    "GROUND_TRUTH_PATH = \"/Users/catarinasilva/Desktop/Lung_Cancer_Treatment_Stages_Final.csv\"\n",
    "INPUT_PATIENTS_PATH = \"/Users/catarinasilva/Desktop/patient_inputs_sample.csv\"\n",
    "\n",
    "run_custom_evaluation_pipeline(\n",
    "    configurations=configs_2,\n",
    "    k_range=k_range,\n",
    "    temperature_range=temperature_range,\n",
    "    n_repeats=n_repeats,\n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/repeated_evaluation_results_OpenAICombinedGemini.csv\",\n",
    "    #grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/results_summary_GeminiCombinedGemini.csv\",\n",
    "    #metrics_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/metrics_and_confusion_matrix.csv\",\n",
    "    #classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/classification_report.csv\",\n",
    "    #confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/confusion_matrix_report.csv\",\n",
    "    #ragas_output= \"/Users/catarinasilva/Desktop/LLM/Final_eval/ragas_summary.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139fb16-b936-49bb-8c54-81d1e026d0b2",
   "metadata": {},
   "source": [
    "#### OpenAIBM25Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eb9d8d7-a4da-4f1c-9234-9ad6a39773ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs_3 = [\n",
    "    {\n",
    "        \"embedding_model\": \"openai\",\n",
    "        \"retrieval_method\": \"bm25\",\n",
    "        \"llm_model\": \"gemini\"\n",
    "    }\n",
    " \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b1bb5f0-555d-4899-a864-effb5faecc15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patients:   0%|                                          | 0/36 [00:00<?, ?it/s]\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:00<00:00, 780.66s/it]\u001b[A\n",
      "Patients:   3%|â–Š                              | 1/36 [13:00<7:35:23, 780.67s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:59<00:00, 899.03s/it]\u001b[A\n",
      "Patients:   6%|â–ˆâ–‹                             | 2/36 [27:59<8:01:50, 850.31s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:16<00:00, 856.42s/it]\u001b[A\n",
      "Patients:   8%|â–ˆâ–ˆâ–Œ                            | 3/36 [42:16<7:49:12, 853.11s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:53<00:00, 893.27s/it]\u001b[A\n",
      "Patients:  11%|â–ˆâ–ˆâ–ˆâ–                           | 4/36 [57:09<7:43:27, 868.98s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:16:44<00:00, 87404.25s/it]\u001b[A\n",
      "Patients:  14%|â–ˆâ–ˆâ–ˆâ–Ž                    | 5/36 [25:13:53<276:11:41, 32074.24s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:57<00:00, 897.18s/it]\u001b[A\n",
      "Patients:  17%|â–ˆâ–ˆâ–ˆâ–ˆ                    | 6/36 [25:28:51<178:57:02, 21474.08s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:13<00:00, 913.95s/it]\u001b[A\n",
      "Patients:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 7/36 [25:44:05<118:50:22, 14752.50s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:34<00:00, 934.25s/it]\u001b[A\n",
      "Patients:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 8/36 [25:59:39<80:31:36, 10353.44s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:45<00:00, 1065.17s/it]\u001b[A\n",
      "Patients:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 9/36 [26:17:24<55:52:24, 7449.79s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:40<00:00, 1060.23s/it]\u001b[A\n",
      "Patients:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 10/36 [26:35:04<39:33:27, 5477.21s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:53<00:00, 1013.93s/it]\u001b[A\n",
      "Patients:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 11/36 [26:51:58<28:33:00, 4111.22s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:18:31<00:00, 87511.04s/it]\u001b[A\n",
      "Patients:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 12/36 [51:10:29<196:32:56, 29482.35s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:08<00:00, 1028.17s/it]\u001b[A\n",
      "Patients:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 13/36 [51:27:38<133:17:19, 20862.59s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:52<00:00, 1072.52s/it]\u001b[A\n",
      "Patients:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 14/36 [51:45:30<90:57:50, 14885.04s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:30<00:00, 1110.11s/it]\u001b[A\n",
      "Patients:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 15/36 [52:04:00<62:36:29, 10732.85s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:40<00:00, 1120.94s/it]\u001b[A\n",
      "Patients:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 16/36 [52:22:41<43:33:13, 7839.68s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:20:42<00:00, 87642.15s/it]\u001b[A\n",
      "Patients:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 17/36 [76:43:23<168:01:28, 31836.26s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:08<00:00, 1028.70s/it]\u001b[A\n",
      "Patients:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 18/36 [77:00:32<112:53:40, 22578.94s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:46<00:00, 946.53s/it]\u001b[A\n",
      "Patients:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 19/36 [77:16:19<75:56:30, 16081.82s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:57<00:00, 1017.51s/it]\u001b[A\n",
      "Patients:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 20/36 [77:33:16<51:22:22, 11558.93s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:43<00:00, 1123.13s/it]\u001b[A\n",
      "Patients:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 21/36 [77:51:59<35:06:36, 8426.45s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:21<00:00, 921.52s/it]\u001b[A\n",
      "Patients:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 22/36 [78:07:21<24:00:37, 6174.10s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:36<00:00, 996.93s/it]\u001b[A\n",
      "Patients:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 23/36 [78:23:58<16:41:06, 4620.53s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:16:22<00:00, 87382.80s/it]\u001b[A\n",
      "Patients:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 24/36 [102:40:21<98:10:47, 29453.98s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:33<00:00, 933.53s/it]\u001b[A\n",
      "Patients:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 25/36 [102:55:54<63:51:03, 20896.71s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [15:21<00:00, 921.58s/it]\u001b[A\n",
      "Patients:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 26/36 [103:11:16<41:23:56, 14903.62s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:16<00:00, 976.29s/it]\u001b[A\n",
      "Patients:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 27/36 [103:27:32<26:48:46, 10725.16s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [16:22<00:00, 982.76s/it]\u001b[A\n",
      "Patients:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 28/36 [103:43:55<17:20:18, 7802.31s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [17:08<00:00, 1028.63s/it]\u001b[A\n",
      "Patients:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 29/36 [104:01:04<11:13:11, 5770.15s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:18:10<00:00, 87490.35s/it]\u001b[A\n",
      "Patients:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30/36 [128:19:14<50:28:40, 30286.78s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [18:28<00:00, 1108.32s/it]\u001b[A\n",
      "Patients:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 31/36 [128:37:43<29:54:25, 21533.11s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [14:19<00:00, 859.92s/it]\u001b[A\n",
      "Patients:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 32/36 [128:52:03<17:02:04, 15331.10s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:59<00:00, 839.68s/it]\u001b[A\n",
      "Patients:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 33/36 [129:06:02<9:09:10, 10983.65s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.23s/it]\u001b[A\n",
      "Patients:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/36 [129:18:49<4:23:56, 7918.42s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:35<00:00, 815.88s/it]\u001b[A\n",
      "Patients:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 35/36 [129:32:24<1:36:27, 5787.67s/it]\u001b[A\n",
      "Configurations:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸš¨] Gemini quota exceeded. Sleeping for 24 hours.\n",
      "[â³ Attempt 1/2] Retrying in 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [24:14:55<00:00, 87295.46s/it]\u001b[A\n",
      "Patients: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [153:47:20<00:00, 15378.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Saved raw results (before metrics) to /Users/catarinasilva/Desktop/LLM/Final_eval/repeated_evaluation_results_OpenAIBM25Gemini.csv\n",
      "CPU times: user 15min 41s, sys: 4min 16s, total: 19min 57s\n",
      "Wall time: 6d 9h 47min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k_range = [5, 7, 10, 15]\n",
    "temperature_range = [0, 0.3, 0.5, 0.7]\n",
    "n_repeats = 10\n",
    "\n",
    "GROUND_TRUTH_PATH = \"/Users/catarinasilva/Desktop/Lung_Cancer_Treatment_Stages_Final.csv\"\n",
    "INPUT_PATIENTS_PATH = \"/Users/catarinasilva/Desktop/patient_inputs_sample.csv\"\n",
    "\n",
    "run_custom_evaluation_pipeline(\n",
    "    configurations=configs_3,\n",
    "    k_range=k_range,\n",
    "    temperature_range=temperature_range,\n",
    "    n_repeats=n_repeats,\n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/repeated_evaluation_results_OpenAIBM25Gemini.csv\",\n",
    "    #grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/results_summary_GeminiCombinedGemini.csv\",\n",
    "    #metrics_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/metrics_and_confusion_matrix.csv\",\n",
    "    #classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/classification_report.csv\",\n",
    "    #confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/confusion_matrix_report.csv\",\n",
    "    #ragas_output= \"/Users/catarinasilva/Desktop/LLM/Final_eval/ragas_summary.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349ecb3-6352-496d-9c63-81514af600a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "393772f1-449f-425f-88a6-bbd54f434e43",
   "metadata": {},
   "source": [
    "#### Fix results best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da7e9b-be5a-4400-a342-e880b572cce4",
   "metadata": {},
   "source": [
    "##### GeminiCombinedGemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fd007b-c0e9-4388-a565-d0fea5f50753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GeminiCombinedGemini = pd.read_csv('/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/repeated_evaluation_results_GeminiCombinedGemini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112b6524-6c7c-4991-b38f-90be81354efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GeminiCombinedGemini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "038a1fbf-6327-4988-83f4-61d4fdec9620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "III        1548\n",
       "ES-SCLC     658\n",
       "IIA         591\n",
       "IIIB        515\n",
       "IIIA        371\n",
       "NaN         324\n",
       "IB          281\n",
       "IIB         280\n",
       "LS-SCLC     238\n",
       "IV          228\n",
       "IIIC        218\n",
       "IVB         170\n",
       "IA          131\n",
       "IVA          94\n",
       "I            67\n",
       "IVC          30\n",
       "II           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GeminiCombinedGemini['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd90580f-3567-4b8e-9187-c95a95fcf04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_stage\n",
      "<class 'str'>    5760\n",
      "Name: count, dtype: int64\n",
      "predicted_stage\n",
      "<class 'str'>      5436\n",
      "<class 'float'>     324\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_GeminiCombinedGemini[\"true_stage\"].apply(type).value_counts())\n",
    "print(df_GeminiCombinedGemini[\"predicted_stage\"].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60d2832c-de37-4dfa-9498-fc5b8087a4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corrigir\n",
    "df_GeminiCombinedGemini_corrigido = correct_predicted_stages(df_GeminiCombinedGemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8395e591-432d-4d86-adfc-5b221f1fc033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['embedding_model', 'retrieval_method', 'llm_model', 'top_k',\n",
       "       'temperature', 'input_idx', 'run_idx', 'T_stage', 'N_stage', 'M_stage',\n",
       "       'cancer_type', 'true_stage', 'predicted_stage', 'ground_truth_answer',\n",
       "       'predicted_treatment', 'raw_output', 'contexts', 'stage_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GeminiCombinedGemini_corrigido.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fd19c8c-83f0-4770-a494-703c6ce40f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       1434\n",
       "IIIA        660\n",
       "ES-SCLC     658\n",
       "IIA         603\n",
       "IIIC        582\n",
       "IA          491\n",
       "IIB         304\n",
       "IB          295\n",
       "IVB         291\n",
       "LS-SCLC     238\n",
       "IVA         120\n",
       "IVC          84\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GeminiCombinedGemini_corrigido['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f524ef3-8f5d-48ec-8916-720f26696c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GeminiCombinedGemini_corrigido.to_csv('/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/repeated_evaluation_results_GeminiCombinedGemini_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "210c62c4-3e8f-44df-b5e5-e07d7f46c9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_1 = df_GeminiCombinedGemini[df_GeminiCombinedGemini['predicted_stage']!=df_GeminiCombinedGemini['true_stage']][['predicted_treatment','predicted_stage', 'true_stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6cf349-f92b-42b4-8e36-55978880282b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4055, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e1610d6-dd04-4c43-8477-232911ea232b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "III        1548\n",
       "IIA         576\n",
       "ES-SCLC     338\n",
       "NaN         324\n",
       "IIIB        254\n",
       "IV          228\n",
       "IVB         170\n",
       "IB          165\n",
       "IIIC        114\n",
       "LS-SCLC      96\n",
       "I            67\n",
       "IIIA         58\n",
       "IA           39\n",
       "IIB          32\n",
       "IVC          30\n",
       "II           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e72afcf1-c857-42de-834c-62610a475355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_2 = df_GeminiCombinedGemini_corrigido[df_GeminiCombinedGemini_corrigido['predicted_stage']!=df_GeminiCombinedGemini_corrigido['true_stage']][['predicted_treatment','predicted_stage', 'true_stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ef8b9a2-7b6a-4173-be0b-3f397589c560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2777, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c06d68d1-9fbd-418d-a122-152c38557897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       700\n",
       "IIA        588\n",
       "ES-SCLC    338\n",
       "IIIC       325\n",
       "IVB        291\n",
       "IB         173\n",
       "IIIA       110\n",
       "LS-SCLC     96\n",
       "IVC         84\n",
       "IA          39\n",
       "IIB         33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6a860-0aea-4f53-8300-d24a96b8f271",
   "metadata": {},
   "source": [
    "##### OpenAICombinedGemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24060da2-92c3-41de-bde6-f5864906f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OpenAICombinedGemini = pd.read_csv('/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/repeated_evaluation_results_OpenAICombinedGemini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d7c272-8a47-4793-9449-9f46d1934f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAICombinedGemini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c6ed12-bcf5-466b-96a6-5758cb90baf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "III        1548\n",
       "ES-SCLC     658\n",
       "IIA         591\n",
       "IIIB        515\n",
       "IIIA        371\n",
       "NaN         324\n",
       "IB          281\n",
       "IIB         280\n",
       "LS-SCLC     238\n",
       "IV          228\n",
       "IIIC        218\n",
       "IVB         170\n",
       "IA          131\n",
       "IVA          94\n",
       "I            67\n",
       "IVC          30\n",
       "II           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAICombinedGemini['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d927de8-ce5d-41d1-ad43-4a6305ec5b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_stage\n",
      "<class 'str'>    5760\n",
      "Name: count, dtype: int64\n",
      "predicted_stage\n",
      "<class 'str'>      5436\n",
      "<class 'float'>     324\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_OpenAICombinedGemini[\"true_stage\"].apply(type).value_counts())\n",
    "print(df_OpenAICombinedGemini[\"predicted_stage\"].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4300b8bd-cde4-4114-8d4a-b656b6ea97db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corrigir\n",
    "df_OpenAICombinedGemini_corrigido = correct_predicted_stages(df_OpenAICombinedGemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fb2f855-82e4-4603-8996-f55642528763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['embedding_model', 'retrieval_method', 'llm_model', 'top_k',\n",
       "       'temperature', 'input_idx', 'run_idx', 'T_stage', 'N_stage', 'M_stage',\n",
       "       'cancer_type', 'true_stage', 'predicted_stage', 'ground_truth_answer',\n",
       "       'predicted_treatment', 'raw_output', 'contexts', 'stage_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAICombinedGemini_corrigido.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401de03e-e5dd-4873-a8d7-62f173da86fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       1434\n",
       "IIIA        660\n",
       "ES-SCLC     658\n",
       "IIA         603\n",
       "IIIC        582\n",
       "IA          491\n",
       "IIB         304\n",
       "IB          295\n",
       "IVB         291\n",
       "LS-SCLC     238\n",
       "IVA         120\n",
       "IVC          84\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAICombinedGemini_corrigido['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a09f1-4414-400e-85a4-61c9cb36b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OpenAICombinedGemini_corrigido.to_csv('/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/repeated_evaluation_results_OpenAICombinedGemini_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8a74a41-7ec5-4049-b884-86104b719f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_3 = df_OpenAICombinedGemini[df_OpenAICombinedGemini['predicted_stage']!=df_OpenAICombinedGemini['true_stage']][['predicted_treatment','predicted_stage', 'true_stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "572e5d82-77f3-4cab-9616-078a5bb33ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4055, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8681c0e4-94da-4edf-8728-0254bf450604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "III        1548\n",
       "IIA         576\n",
       "ES-SCLC     338\n",
       "NaN         324\n",
       "IIIB        254\n",
       "IV          228\n",
       "IVB         170\n",
       "IB          165\n",
       "IIIC        114\n",
       "LS-SCLC      96\n",
       "I            67\n",
       "IIIA         58\n",
       "IA           39\n",
       "IIB          32\n",
       "IVC          30\n",
       "II           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "812afa3b-3f89-4063-b0d8-9f1a423d3cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_4 = df_OpenAICombinedGemini_corrigido[df_OpenAICombinedGemini_corrigido['predicted_stage']!=df_OpenAICombinedGemini_corrigido['true_stage']][['predicted_treatment','predicted_stage', 'true_stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cefe281-fa78-4186-8ac3-e4f3fe2fa167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2777, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e643982-7763-400f-9126-87ac945acbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       700\n",
       "IIA        588\n",
       "ES-SCLC    338\n",
       "IIIC       325\n",
       "IVB        291\n",
       "IB         173\n",
       "IIIA       110\n",
       "LS-SCLC     96\n",
       "IVC         84\n",
       "IA          39\n",
       "IIB         33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_4['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7878428-6b86-4899-85f9-fc30701f1aee",
   "metadata": {},
   "source": [
    "##### OpenAIBM25Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "706e1361-30c0-43b6-8f72-164b97fdfc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OpenAIBM25Gemini = pd.read_csv('/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/repeated_evaluation_results_OpenAIBM25Gemini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ab82e8a-997d-4305-a196-ea28044579b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAIBM25Gemini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77c0216e-545d-44ab-9f78-79a4e59bbca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       1468\n",
       "ES-SCLC     660\n",
       "IIIA        645\n",
       "IIA         582\n",
       "IIIC        533\n",
       "IA          500\n",
       "IIB         327\n",
       "IVB         294\n",
       "IB          286\n",
       "LS-SCLC     250\n",
       "IVA         124\n",
       "IVC          91\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAIBM25Gemini['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe7009f-27b7-42fd-bece-1ea66415500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_stage\n",
      "<class 'str'>    5760\n",
      "Name: count, dtype: int64\n",
      "predicted_stage\n",
      "<class 'str'>    5760\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_OpenAIBM25Gemini[\"true_stage\"].apply(type).value_counts())\n",
    "print(df_OpenAIBM25Gemini[\"predicted_stage\"].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96d65e54-a346-47a3-8f26-f3b5e3ad3586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corrigir\n",
    "df_OpenAIBM25Gemini_corrigido = correct_predicted_stages(df_OpenAIBM25Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "541e41f4-6ed9-4bb4-8bc7-a42bc546b49b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['embedding_model', 'retrieval_method', 'llm_model', 'top_k',\n",
       "       'temperature', 'input_idx', 'run_idx', 'T_stage', 'N_stage', 'M_stage',\n",
       "       'cancer_type', 'true_stage', 'predicted_stage', 'ground_truth_answer',\n",
       "       'predicted_treatment', 'raw_output', 'contexts', 'stage_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAIBM25Gemini_corrigido.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2738752d-f485-4527-b41c-28834dfb02c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       1468\n",
       "ES-SCLC     660\n",
       "IIIA        645\n",
       "IIA         582\n",
       "IIIC        533\n",
       "IA          500\n",
       "IIB         327\n",
       "IVB         294\n",
       "IB          286\n",
       "LS-SCLC     250\n",
       "IVA         124\n",
       "IVC          91\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OpenAIBM25Gemini_corrigido['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdd1b4af-b207-4326-9483-733e0b44847b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_OpenAIBM25Gemini_corrigido.to_csv('/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/repeated_evaluation_results_OpenAIBM25Gemini_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "071c8994-e756-4835-8750-aebf48150600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_5 = df_OpenAIBM25Gemini[df_OpenAIBM25Gemini['predicted_stage']!=df_OpenAIBM25Gemini['true_stage']][['predicted_treatment','predicted_stage', 'true_stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1aebc0f-ec16-4baa-9fc2-b691c6bd6e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4055, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94dcf56a-5a93-438a-9bfd-3c913c7a42fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "III        1548\n",
       "IIA         576\n",
       "ES-SCLC     338\n",
       "NaN         324\n",
       "IIIB        254\n",
       "IV          228\n",
       "IVB         170\n",
       "IB          165\n",
       "IIIC        114\n",
       "LS-SCLC      96\n",
       "I            67\n",
       "IIIA         58\n",
       "IA           39\n",
       "IIB          32\n",
       "IVC          30\n",
       "II           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_5['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "742e67d5-0415-4a87-aa79-3e2a907a664c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_6 = df_OpenAIBM25Gemini_corrigido[df_OpenAIBM25Gemini_corrigido['predicted_stage']!=df_OpenAIBM25Gemini_corrigido['true_stage']][['predicted_treatment','predicted_stage', 'true_stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c43e83e-d789-4ff0-8a04-07ae12d2cffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2777, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b99353f-2106-4346-9108-352620ef4e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_stage\n",
       "IIIB       700\n",
       "IIA        588\n",
       "ES-SCLC    338\n",
       "IIIC       325\n",
       "IVB        291\n",
       "IB         173\n",
       "IIIA       110\n",
       "LS-SCLC     96\n",
       "IVC         84\n",
       "IA          39\n",
       "IIB         33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_6['predicted_stage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab2d949-8dd1-412f-b913-b0c58d85cdfb",
   "metadata": {},
   "source": [
    "### Eval Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f91fda2-821a-4a1b-9a59-21788590e231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# === Rate limit parameters ===\n",
    "REQUEST_TIMESTAMPS = deque()\n",
    "TOKENS_USED = 0\n",
    "MAX_REQUESTS_PER_MINUTE = 2500\n",
    "MAX_TOKENS_PER_MINUTE = 250000\n",
    "\n",
    "def enforce_rate_limits(token_count):\n",
    "    global REQUEST_TIMESTAMPS, TOKENS_USED\n",
    "    current_time = time.time()\n",
    "\n",
    "    while REQUEST_TIMESTAMPS and (current_time - REQUEST_TIMESTAMPS[0]) > 60:\n",
    "        REQUEST_TIMESTAMPS.popleft()\n",
    "\n",
    "    requests_remaining = MAX_REQUESTS_PER_MINUTE - len(REQUEST_TIMESTAMPS)\n",
    "    tokens_remaining = MAX_TOKENS_PER_MINUTE - TOKENS_USED\n",
    "\n",
    "    if requests_remaining <= 0 or tokens_remaining < token_count:\n",
    "        if REQUEST_TIMESTAMPS:\n",
    "            sleep_time = max(1, 60 - (current_time - REQUEST_TIMESTAMPS[0]))\n",
    "        else:\n",
    "            sleep_time = 60\n",
    "        print(f\"[â³] Rate limit reached. Sleeping for {sleep_time:.2f} seconds.\")\n",
    "        time.sleep(sleep_time)\n",
    "        TOKENS_USED = 0  # Reset usage after pause\n",
    "\n",
    "    REQUEST_TIMESTAMPS.append(current_time)\n",
    "    TOKENS_USED += token_count\n",
    "\n",
    "# === Chunking logic ===\n",
    "def chunk_dataset(dataset, chunk_size):\n",
    "    for i in range(0, len(dataset), chunk_size):\n",
    "        yield dataset.select(range(i, min(i + chunk_size, len(dataset))))\n",
    "\n",
    "# === RAGAS evaluation per group with rate limit ===\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from ragas.evaluation import EvaluationResult\n",
    "\n",
    "def compute_ragas_safe(dataset, tokens_per_example=400):\n",
    "    try:\n",
    "        enforce_rate_limits(len(dataset) * tokens_per_example)\n",
    "        return evaluate(\n",
    "            dataset,\n",
    "            metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "            llm=llm,\n",
    "            embeddings=embeddings\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[âŒ RAGAS error] {e}\")\n",
    "        return {\n",
    "            \"faithfulness\": [np.nan] * len(dataset),\n",
    "            \"answer_relevancy\": [np.nan] * len(dataset),\n",
    "            \"context_precision\": [np.nan] * len(dataset),\n",
    "            \"context_recall\": [np.nan] * len(dataset)\n",
    "        }\n",
    "\n",
    "def evaluate_from_csv(input_csv_path, output_path, grouped_output_path,\n",
    "                           metrics_output_path, classification_report_output_path,\n",
    "                           confusion_matrices_csv_path, ragas_output_path):\n",
    "    import pandas as pd\n",
    "    from datasets import Dataset\n",
    "    from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "    from ragas import evaluate\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "    from sklearn.utils.multiclass import unique_labels\n",
    "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "    from rouge_score import rouge_scorer\n",
    "    from collections import defaultdict\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    df[\"stage_match\"] = df[\"true_stage\"] == df[\"predicted_stage\"]\n",
    "\n",
    "    # Compute BERTScore\n",
    "    preds = df[\"raw_output\"].fillna(\"\").tolist()\n",
    "    refs = df[\"ground_truth_answer\"].fillna(\"\").tolist()\n",
    "    f1_scores = compute_bertscore_in_batches(preds, refs)\n",
    "    df[\"bertscore_f1\"] = f1_scores\n",
    "\n",
    "    # Compute BLEU and ROUGE-L\n",
    "    smoother = SmoothingFunction()\n",
    "    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    bleu_scores, rouge_l_scores = [], []\n",
    "\n",
    "    for pred, ref in tqdm(zip(preds, refs), total=len(preds), desc=\"Scoring\"):\n",
    "        bleu = sentence_bleu([ref.split()], pred.split(), smoothing_function=smoother.method1)\n",
    "        rouge_l = rouge.score(ref, pred)[\"rougeL\"].fmeasure\n",
    "        bleu_scores.append(bleu)\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "\n",
    "    df[\"bleu\"] = bleu_scores\n",
    "    df[\"rougeL\"] = rouge_l_scores\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Grouped metrics\n",
    "    grouped = df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\", \"top_k\", \"temperature\"])[\n",
    "        [\"stage_match\", \"bertscore_f1\", \"bleu\", \"rougeL\"] #, \"top_k\", \"temperature\"\n",
    "    ].agg([\"mean\", \"std\"]).reset_index()\n",
    "    grouped.columns = [\"_\".join(col).strip() if isinstance(col, tuple) else col for col in grouped.columns.values]\n",
    "    grouped.to_csv(grouped_output_path, index=False)\n",
    "\n",
    "    # Confusion matrix and classification report\n",
    "    metrics = []\n",
    "    classification_reports = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    labels = unique_labels(df[\"true_stage\"], df[\"predicted_stage\"])\n",
    "\n",
    "    for name, group in tqdm(df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\", \"top_k\", \"temperature\"]), desc=\"Metrics\"): #, \"top_k\", \"temperature\"\n",
    "        cm = confusion_matrix(group[\"true_stage\"], group[\"predicted_stage\"], labels=labels)\n",
    "        acc = accuracy_score(group[\"true_stage\"], group[\"predicted_stage\"])\n",
    "        f1 = f1_score(group[\"true_stage\"], group[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "        prec = precision_score(group[\"true_stage\"], group[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "        rec = recall_score(group[\"true_stage\"], group[\"predicted_stage\"], average='macro', zero_division=0)\n",
    "\n",
    "        report = classification_report(group[\"true_stage\"], group[\"predicted_stage\"], output_dict=True, zero_division=0)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        for i, val in zip([\"embedding_model\", \"retrieval_method\", \"llm_model\", \"top_k\", \"temperature\"], name): #, \"top_k\", \"temperature\"\n",
    "            report_df[i] = val\n",
    "        classification_reports.append(report_df)\n",
    "\n",
    "        metrics.append({\n",
    "            \"embedding_model\": name[0],\n",
    "            \"retrieval_method\": name[1],\n",
    "            \"llm_model\": name[2],\n",
    "            \"top_k\": name[3],\n",
    "            \"temperature\": name[4],\n",
    "            \"accuracy\": acc,\n",
    "            \"f1_score\": f1,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"confusion_matrix\": cm.tolist()\n",
    "        })\n",
    "\n",
    "        cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "        cm_df.index.name = 'True_Stage'\n",
    "        cm_df[\"embedding_model\"] = name[0]\n",
    "        cm_df[\"retrieval_method\"] = name[1]\n",
    "        cm_df[\"llm_model\"] = name[2]\n",
    "        cm_df[\"top_k\"] = name[3]\n",
    "        cm_df[\"temperature\"] = name[4]\n",
    "        confusion_matrices.append(cm_df)\n",
    "\n",
    "    \n",
    "    pd.DataFrame(metrics).to_csv(metrics_output_path, index=False)\n",
    "    pd.concat(classification_reports).reset_index().to_csv(classification_report_output_path, index=False)\n",
    "    pd.concat(confusion_matrices).to_csv(confusion_matrices_csv_path, index=True)\n",
    "\n",
    "    # Compute RAGAS\n",
    "    print(\"\\n[âœ”] Computing RAGAS...\")\n",
    "    ragas_summary = []\n",
    "    grouped = df.groupby([\"embedding_model\", \"retrieval_method\", \"llm_model\", \"top_k\", \"temperature\"])\n",
    "\n",
    "    for name, group in tqdm(grouped, desc=\"RAGAS Evaluation\"):\n",
    "        records = []\n",
    "        for _, row in group.iterrows():\n",
    "            try:\n",
    "                contexts = eval(row[\"contexts\"]) if isinstance(row[\"contexts\"], str) else row[\"contexts\"]\n",
    "            except Exception as e:\n",
    "                contexts = []\n",
    "                print(f\"[âš ] Invalid context eval: {e}\")\n",
    "\n",
    "            records.append({\n",
    "                \"question\": \"Based on the patient data and TMN staging what is the exact stage of the cancer and the indicated course of treatment?\",\n",
    "                \"contexts\": contexts,\n",
    "                \"answer\": row[\"raw_output\"],\n",
    "                \"ground_truth\": row[\"ground_truth_answer\"]\n",
    "            })\n",
    "\n",
    "        dataset = Dataset.from_list(records)\n",
    "        scores = defaultdict(list)\n",
    "\n",
    "        for batch in chunk_dataset(dataset, chunk_size=100):\n",
    "            ragas_result = compute_ragas_safe(batch)\n",
    "\n",
    "            # Handle both dict and EvaluationResult formats safely\n",
    "            if isinstance(ragas_result, dict):\n",
    "                result_dict = ragas_result\n",
    "            else:\n",
    "                result_dict = {\n",
    "                    \"faithfulness\": ragas_result[\"faithfulness\"],\n",
    "                    \"answer_relevancy\": ragas_result[\"answer_relevancy\"],\n",
    "                    \"context_precision\": ragas_result[\"context_precision\"],\n",
    "                    \"context_recall\": ragas_result[\"context_recall\"],\n",
    "                }\n",
    "\n",
    "            for k, v in result_dict.items():\n",
    "                scores[k].extend(v)\n",
    "\n",
    "        ragas_summary.append({\n",
    "            \"embedding_model\": name[0],\n",
    "            \"retrieval_method\": name[1],\n",
    "            \"llm_model\": name[2],\n",
    "            \"top_k\": name[3],\n",
    "            \"temperature\": name[4],\n",
    "            \"RAGAS_Faithfulness\": np.nanmean(scores[\"faithfulness\"]),\n",
    "            \"RAGAS_AnswerRelevancy\": np.nanmean(scores[\"answer_relevancy\"]),\n",
    "            \"RAGAS_ContextPrecision\": np.nanmean(scores[\"context_precision\"]),\n",
    "            \"RAGAS_ContextRecall\": np.nanmean(scores[\"context_recall\"]),\n",
    "        })\n",
    "\n",
    "    pd.DataFrame(ragas_summary).to_csv(ragas_output_path, index=False)\n",
    "    print(\"[âœ”] Finished RAGAS evaluation safely.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca2c56-b66b-4e10-877d-5c6060e8d800",
   "metadata": {},
   "source": [
    "##### GeminiCombinedGemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d4347ae-5c81-4bea-bfca-0e58d81ec39a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[âœ”] Computing RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:   0%|                                  | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42ddba7e3554b63a2cb9d0a85db1d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37beac46b56f433c908e4916b2ff3f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7297a0246946bfa1fb483ff8d2be3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[348]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32aaf8d890d4ef9adf9ee1132526fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[131]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[136]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[140]: TimeoutError()\n",
      "RAGAS Evaluation:   6%|â–ˆâ–Ž                   | 1/16 [44:37<11:09:27, 2677.82s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb348d0bc845482c86cc89e3d8ab28e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[32]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[35]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[40]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[56]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b38a66f2b74351b95b129440249933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[15]: RateLimitError(Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2025-01-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}})\n",
      "ERROR:ragas.executor:Exception raised in Job[255]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b38238f144423195981fd7ff0358f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55f5fd153c64d368bdab840584f1fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[224]: TimeoutError()\n",
      "RAGAS Evaluation:  12%|â–ˆâ–ˆâ–                | 2/16 [1:30:55<10:38:32, 2736.61s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2824eadcdfa4cc193c552979a0c15f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[320]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[324]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[328]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[332]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[336]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7356da0cbaa241008e15beb3a829a55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28310a24d1b9418e8b5e19ca1aeff852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[200]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefee99d6af842d98384a6b0b5368820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  19%|â–ˆâ–ˆâ–ˆâ–Š                | 3/16 [2:13:39<9:35:49, 2657.66s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d2cdfc94ed4d29a80fc29bb881ad5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1548774b2243dcbf4b94d8151acf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[308]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdc1db4a9654e8e86a9386e2714bc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6881e0e31cb64574a2534aa772deb21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 4/16 [2:57:12<8:48:03, 2640.29s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3723fea3ae5941cabc449662561195bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[172]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1950ef9b20417fb9cfcea4d289c7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[48]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[360]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edc30cfad44485b9ca01837dfbce46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bf8055c2f64984a833cc0df608dcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[200]: TimeoutError()\n",
      "RAGAS Evaluation:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 5/16 [3:53:36<8:53:10, 2908.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5902606428c041be8f373d92f595fe35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44926a61a1f74422a9463dc069518bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[211]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9096318c10634b1681f64a7f6fc0f8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31cfec2e3804926ae508e975aa35adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 6/16 [4:48:43<8:27:17, 3043.75s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c34c29764f4e2680f707ae16f7a6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91897d843ffa427a84d22466ac544d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a688a304aa4eb48834eaf86f191494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0a32b070404157a6d9788cacb4290e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 7/16 [5:43:44<7:49:11, 3127.90s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5beb4fad2dca49e0b3b362636736ce83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[15]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[203]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12c2269db5b4e8eb9e004dd7ad02ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99af553bd4c04130bdd57b4c6ed4e0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce60f3f46a9545d78a7229ea58e48d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 8/16 [6:38:03<7:02:38, 3169.78s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3c830b960343858f6df27c22b43707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[68]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46059b3ea4534025b4cf3609b52c9569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a879a9aa1746f280c3de5e4d9a6334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[296]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[300]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[303]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[304]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[307]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[312]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[315]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f74ba8cac54ba191e4d31c3c1b74be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[4]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "RAGAS Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 9/16 [7:53:38<6:59:36, 3596.61s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efdb7a65cd84f5fb60d60e9a6828713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[151]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c24b7c9f59244f2a1846ea906d0542d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[23]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[68]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8d784ce7584e7d97efbdd336263467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[19]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[44]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[319]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[327]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b632ab09cf74d20b7bbf4f2701ae0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[128]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "RAGAS Evaluation:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 10/16 [9:10:58<6:31:52, 3918.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e68373c8e94fd1afcbb87d9a9cf560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[380]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b576747c7e4464dbfb4137c370fcfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[56]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9c7344c5b94b3d86b1a1388042f92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[268]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623ebb696062465d8f4d9a5c51fc67df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "RAGAS Evaluation:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/16 [10:28:31<5:45:16, 4143.30s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba394516c1d4336b2d12f38bb69287a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[168]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[331]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[364]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[380]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[384]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded4f48e1b1444059c97bf986c5b7476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[79]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c76958f256a4e92919c81d0f16c3f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[100]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[116]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[252]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b7571bf4ff417aa2907b92882ae45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 12/16 [11:44:55<4:45:09, 4277.34s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aca56359f1243eb9168ce7352d24e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[28]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[32]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[35]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[39]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[40]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[47]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[84]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[103]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[107]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[127]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[136]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[191]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[242]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[348]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[366]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[379]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[380]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[384]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64284e19646047f79289c97fc17dc61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[19]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[30]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[34]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[38]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[42]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[55]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[62]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[74]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[82]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[94]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[98]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[118]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[134]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[140]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[150]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[162]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[170]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[194]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[222]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[238]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[246]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[250]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[262]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[266]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[282]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[286]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[294]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[300]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[306]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[315]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[318]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[338]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[346]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517d191b4ab94f47995b810539a2c2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[20]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[28]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[70]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[75]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[168]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[207]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[224]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[280]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[324]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[348]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7837ffe6114f168ea4608096a241e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[46]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[58]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[60]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[62]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[66]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[70]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[86]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[142]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[158]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[174]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[188]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[202]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "RAGAS Evaluation:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 13/16 [13:34:59<4:09:06, 4982.30s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f46ee21a9af4dd69da9e149cc5851bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[32]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[48]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[51]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[83]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[100]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[176]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[202]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[214]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[240]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[246]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[254]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[274]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[278]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[282]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[286]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[294]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[306]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[318]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[346]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d7fb7595eb4092af8e0410b45dfdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[54]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[98]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[110]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[202]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[214]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[232]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[298]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[354]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[362]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[366]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2456750c0154cfb9544155627541eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[20]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[32]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[152]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[231]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[252]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[264]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[271]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[272]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[276]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[280]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[308]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[311]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[312]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[320]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[323]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[340]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a68f62a36e149eabe1fe9f3d857af85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[62]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[139]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "RAGAS Evaluation:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/16 [15:25:12<3:02:29, 5474.74s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb96712fb244d14aa89070a11e3b984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[4]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[28]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[158]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[222]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[234]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[238]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[254]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[294]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[302]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[306]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[350]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[358]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[375]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79a1202f42e484f8a68db2b5abc33ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[12]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[30]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[38]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[50]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[54]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[62]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[74]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[94]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[130]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[138]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[142]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[146]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[154]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[162]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[182]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[190]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[194]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[202]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[218]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[230]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[242]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[247]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[258]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[266]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[286]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[294]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[302]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[318]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[338]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[342]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[350]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[354]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[358]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[362]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[370]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2064ef5916ab4c95b8c384e0429a7ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[0]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[7]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[28]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[126]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[158]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[162]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[186]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[190]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[194]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[202]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[218]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[222]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[226]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[242]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[258]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[278]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[282]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[290]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[302]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[364]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41367d324afd489e8ae5ea49cb76af34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[50]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[70]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[128]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[150]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[166]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[170]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[186]: TimeoutError()\n",
      "RAGAS Evaluation:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 15/16 [17:12:49<1:36:10, 5770.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd86bcb628824d109c161906779e7a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[124]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[230]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[274]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[334]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[336]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845de6c67b8e47c288ea99358f72a598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[34]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[90]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[144]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[216]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[234]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[258]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[262]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[263]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[274]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[282]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[318]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[322]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[330]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[334]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[342]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[350]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[354]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[362]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[366]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48ab66daf3f4d9a877ec0dd49f7b68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[31]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[44]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[48]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[59]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[60]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[64]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[100]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[103]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[159]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[175]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[180]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[204]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[220]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[232]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[296]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[306]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[332]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[356]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff57005d139490a972f31dc6d596ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[0]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[23]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[63]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[79]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[100]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[116]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[154]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[211]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[215]: TimeoutError()\n",
      "RAGAS Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [19:01:24<00:00, 4280.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Finished RAGAS evaluation safely.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_from_csv(\n",
    "    input_csv_path = \"/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/repeated_evaluation_results_GeminiCombinedGemini_fixed.csv\", \n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/repeated_evaluation_results.csv\",\n",
    "    grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/results_summary.csv\",\n",
    "    metrics_output_path=\"//Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/metrics_and_confusion_matrix.csv\",\n",
    "    classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/classification_report.csv\",\n",
    "    confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/confusion_matrix_report.csv\",\n",
    "    ragas_output_path= \"/Users/catarinasilva/Desktop/LLM/Final_eval/GeminiCombinedGemini/ragas_summary.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5095d-7320-4225-bf24-6caa3ce4798f",
   "metadata": {},
   "source": [
    "##### OpenAICombinedGemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a7d3908-bdc4-4f2e-a075-08937153dac2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERTScore batches:   0%|                                 | 0/58 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   2%|â–                        | 1/58 [00:51<49:21, 51.95s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   3%|â–Š                        | 2/58 [01:43<48:10, 51.61s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   5%|â–ˆâ–Ž                       | 3/58 [02:31<45:50, 50.00s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   7%|â–ˆâ–‹                       | 4/58 [03:19<44:26, 49.39s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   9%|â–ˆâ–ˆâ–                      | 5/58 [04:10<44:09, 49.99s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  10%|â–ˆâ–ˆâ–Œ                      | 6/58 [05:01<43:24, 50.08s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  12%|â–ˆâ–ˆâ–ˆ                      | 7/58 [05:54<43:20, 51.00s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  14%|â–ˆâ–ˆâ–ˆâ–                     | 8/58 [06:46<42:56, 51.52s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  16%|â–ˆâ–ˆâ–ˆâ–‰                     | 9/58 [07:39<42:20, 51.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 10/58 [08:31<41:39, 52.07s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 11/58 [09:23<40:41, 51.94s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 12/58 [10:16<40:01, 52.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 13/58 [11:08<39:14, 52.32s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 14/58 [12:02<38:42, 52.79s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 15/58 [12:56<38:04, 53.12s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 16/58 [13:49<37:06, 53.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 17/58 [14:44<36:42, 53.71s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 18/58 [15:38<35:53, 53.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 19/58 [16:34<35:19, 54.36s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 20/58 [17:28<34:18, 54.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 21/58 [18:23<33:42, 54.66s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 22/58 [19:17<32:40, 54.47s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 23/58 [20:12<31:47, 54.49s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 24/58 [21:07<30:54, 54.55s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 25/58 [22:02<30:08, 54.81s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 26/58 [22:54<28:44, 53.88s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 27/58 [23:45<27:20, 52.92s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 28/58 [24:36<26:16, 52.56s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 29/58 [25:27<25:07, 51.99s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 30/58 [26:19<24:14, 51.93s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 31/58 [27:09<23:11, 51.55s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 32/58 [28:00<22:14, 51.33s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 33/58 [28:53<21:37, 51.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 34/58 [29:45<20:41, 51.72s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 35/58 [30:35<19:40, 51.33s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 36/58 [31:28<18:57, 51.70s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 37/58 [32:19<18:01, 51.51s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 38/58 [33:10<17:10, 51.52s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 39/58 [34:02<16:22, 51.69s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 40/58 [34:54<15:31, 51.76s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 41/58 [35:46<14:40, 51.81s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 42/58 [36:39<13:51, 51.96s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 43/58 [37:31<13:00, 52.06s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/58 [38:25<12:17, 52.66s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/58 [39:15<11:16, 52.03s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 46/58 [40:04<10:11, 50.97s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 47/58 [40:53<09:14, 50.41s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 48/58 [41:43<08:22, 50.23s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 49/58 [42:35<07:36, 50.75s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50/58 [43:25<06:44, 50.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 51/58 [44:13<05:49, 49.92s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 52/58 [45:02<04:57, 49.56s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/58 [45:52<04:08, 49.64s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 54/58 [46:42<03:19, 49.89s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55/58 [47:31<02:28, 49.61s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 56/58 [48:21<01:39, 49.64s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 57/58 [49:12<00:50, 50.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [49:43<00:00, 51.44s/it]\n",
      "Scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5760/5760 [02:52<00:00, 33.39it/s]\n",
      "Metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 94.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[âœ”] Computing RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:   0%|                                  | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6afb0fc95a94f9291f5214b318a617b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7458f0c1bee34f23886496874375d775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[128]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[232]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[392]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acee35fe823a4d0f908569acbf3b87a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f947c199a3ee443f9b851f30d23c72d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:   6%|â–ˆâ–Ž                   | 1/16 [46:56<11:44:13, 2816.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cdc113d56f411a9f753b1c25db3a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[268]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b3cb1daa3040fea48c1472ab436b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8494f7bfba4652b039bf14fb6f496d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfef8b37fc0f4b0885fbe4d7f2f983b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  12%|â–ˆâ–ˆâ–                | 2/16 [1:31:28<10:37:21, 2731.54s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9486ecc7ce0644f4881029b00ee57075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[364]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[380]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[384]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53214d56a43e4de89866776d63d3648c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ec7edc428c462a97cbc2c2e21f019b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[172]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[180]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[263]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b2ce6b0cda46fd80393165b2c04024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[12]: TimeoutError()\n",
      "RAGAS Evaluation:  19%|â–ˆâ–ˆâ–ˆâ–Š                | 3/16 [2:15:51<9:45:01, 2700.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e74080299047cfac449847ca1aaa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fb1cefa30646d5b4292a32ee33ae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3de9d4642784df5a6274f2875279a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19713c9ed9f473eab5d8e5ce96381e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[220]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[224]: TimeoutError()\n",
      "RAGAS Evaluation:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 4/16 [3:02:23<9:07:16, 2736.37s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9944916c43b140abaf46b9fdead52b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3771458205df4d1db86d042bcb97a238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[307]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e9017d947a457ab2d1d3562bc6584d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7189da21b2ed4ffba77bcd701f979de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[144]: TimeoutError()\n",
      "RAGAS Evaluation:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 5/16 [3:57:33<8:59:34, 2943.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce15b8108d9a4a2690aa1d359f1491e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[380]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[388]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[396]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd2c48ea9e04753b4c5156b5b30355c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[284]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f8c82c469841a08d731a550b0b038a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[84]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df749712c769465198ee4074496e4824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 6/16 [4:56:18<8:43:30, 3141.05s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8372183a34a4fdfb3edb720313c5084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8938a2cb8f974240a98e513b4d05855c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[360]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa21da38185e4364bdf0ae32c0fac9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[324]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02de547960464c3fa5a55aedc60302ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 7/16 [5:52:18<8:01:52, 3212.53s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef577ea08cd43e5b36c234d6ee040ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20ea814588f4bc58ef77f9798227311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47fa77ffefb49d880c5f2956009b61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaa59cd0aca43979eac79aefea68635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 8/16 [6:47:28<7:12:30, 3243.83s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53801876f1b4c3d9ae35a1beedceb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[259]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde9883959d74bcbaf68aeed4da9175d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[64]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[155]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[156]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[348]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0b0cf450834a89b32d6017eadd28f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[220]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eac69be22b4d5289c3322b0cfaef58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[23]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[134]: TimeoutError()\n",
      "RAGAS Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 9/16 [8:03:21<7:06:11, 3653.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2b6316bbbf453d8b62b456199b2829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[91]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[115]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[156]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[171]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[183]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[187]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[192]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[215]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[272]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[287]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[336]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029cb19a65d2413e87ea4889b4028354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[63]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[123]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[152]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c85c7ef38d049fab92ccc58192c6f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[87]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[88]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1f9a9048d94174bc43fffc308ecaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 10/16 [9:18:45<6:32:10, 3921.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da782e8b73f44970b102e2ff3a01f85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[135]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[180]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[192]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[280]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[283]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[284]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[288]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[300]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[335]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d5d42e315f46ecbb4367e64f7b8a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[164]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[167]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[212]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[268]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[308]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[360]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d695b00d9f9448f8b19b7888a116a653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[220]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[264]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[311]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[320]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f9549827544aafaf6c93e95e2c5cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/16 [10:35:14<5:43:50, 4126.06s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d70f74b05e40369890d6d49134e941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc48599d4fa54ec894e8e0de0e59cd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[160]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[348]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977d1ec9dc324053b73ecddb4db180be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[220]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c887d60ba8b4fa899c0fcc089251e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[208]: TimeoutError()\n",
      "RAGAS Evaluation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 12/16 [11:52:25<4:45:18, 4279.60s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bcbfa01c6244fea8e7718a7e7d6764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[178]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[214]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[242]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[286]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[290]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[294]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[310]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[344]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6707bf9a663841e29a159c5bbb0df144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[23]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[40]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[43]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[52]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[67]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[76]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[80]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[91]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[147]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[155]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[184]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[203]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[208]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[274]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[323]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[332]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54156d855c244741ba2233c88a90fc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[4]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[23]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[96]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[160]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[222]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[260]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[263]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[264]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[272]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[295]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[300]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[319]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[335]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[351]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[356]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[372]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cca6955d4f349db863606af0b942c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[34]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[48]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[86]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[148]: TimeoutError()\n",
      "RAGAS Evaluation:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 13/16 [13:40:54<4:07:45, 4955.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d51e1cb2e04e9da231fb5ba00553f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[12]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[39]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[60]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[111]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[140]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[152]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[164]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[210]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[214]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[226]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[262]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[270]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[290]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[298]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[302]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[334]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[338]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[342]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[346]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[350]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[354]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[358]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[366]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f01dcba5c67435cb1a812bd46f8c155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[18]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[327]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f3be7336bb4b4b927207d85a2f99b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[28]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[68]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[143]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[179]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[216]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[240]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[248]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[271]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[324]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[332]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[356]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de49ff300cd3405d98870304da22d6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[8]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[84]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[100]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[143]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[192]: TimeoutError()\n",
      "RAGAS Evaluation:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/16 [15:31:06<3:01:50, 5455.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e3f35c16e94d41ab7b27e1f49c54ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[222]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[262]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[292]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[295]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[335]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[372]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2223f9112dba41a5bf88f47cc5f8c062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[86]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[176]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[186]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[210]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[218]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[248]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[268]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[303]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[320]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbadea486c8642de8b5398a0af87e4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[8]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[94]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[151]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[182]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[184]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[194]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[204]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[254]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[282]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[312]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[328]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cf8bc8737e4e9696e3682efeb68209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[194]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "RAGAS Evaluation:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 15/16 [17:22:06<1:36:58, 5818.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600f086b500b4019aa15b579540bb3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[108]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[124]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[127]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[252]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[284]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[288]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[300]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[384]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7277ae7feb412ab96b69b5d35f960f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[52]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[68]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[142]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[162]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[210]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[223]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[250]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[274]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[351]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e59bf38a11d47f1a290901a94d060b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[135]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[214]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[230]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[240]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[247]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[252]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[256]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[260]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[280]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[282]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[287]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[292]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[319]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[324]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[331]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[336]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[338]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[342]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86cbcbc65f14deda0976014dfc0d7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[30]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[168]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[187]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[194]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "RAGAS Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [19:13:39<00:00, 4326.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Finished RAGAS evaluation safely.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_from_csv(\n",
    "    input_csv_path = \"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/repeated_evaluation_results_OpenAICombinedGemini_fixed.csv\", \n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/repeated_evaluation_results.csv\",\n",
    "    grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/results_summary.csv\",\n",
    "    metrics_output_path=\"//Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/metrics_and_confusion_matrix.csv\",\n",
    "    classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/classification_report.csv\",\n",
    "    confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/confusion_matrix_report.csv\",\n",
    "    ragas_output_path= \"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAICombinedGemini/ragas_summary.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2e0d7-6316-4fc4-8013-e9202b9f46e9",
   "metadata": {},
   "source": [
    "##### OpenAIBM25Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4088d07-5a35-431a-83a6-20f94468d68a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERTScore batches:   0%|                                 | 0/58 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   2%|â–                        | 1/58 [00:49<47:12, 49.69s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   3%|â–Š                        | 2/58 [01:36<44:43, 47.92s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   5%|â–ˆâ–Ž                       | 3/58 [02:25<44:14, 48.26s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   7%|â–ˆâ–‹                       | 4/58 [03:16<44:41, 49.65s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:   9%|â–ˆâ–ˆâ–                      | 5/58 [04:06<43:50, 49.63s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  10%|â–ˆâ–ˆâ–Œ                      | 6/58 [04:54<42:33, 49.11s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  12%|â–ˆâ–ˆâ–ˆ                      | 7/58 [05:46<42:25, 49.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  14%|â–ˆâ–ˆâ–ˆâ–                     | 8/58 [06:35<41:34, 49.89s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  16%|â–ˆâ–ˆâ–ˆâ–‰                     | 9/58 [07:26<40:57, 50.16s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 10/58 [08:19<40:40, 50.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 11/58 [09:11<40:16, 51.42s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 12/58 [10:04<39:45, 51.86s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 13/58 [10:56<38:51, 51.81s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 14/58 [11:47<37:56, 51.73s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 15/58 [12:39<37:06, 51.77s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 16/58 [13:32<36:20, 51.92s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 17/58 [14:22<35:16, 51.61s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 18/58 [15:14<34:20, 51.51s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 19/58 [16:04<33:17, 51.22s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 20/58 [16:56<32:35, 51.47s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 21/58 [17:48<31:51, 51.65s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 22/58 [18:39<30:50, 51.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 23/58 [19:33<30:20, 52.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 24/58 [20:25<29:34, 52.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 25/58 [21:18<28:47, 52.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 26/58 [22:13<28:25, 53.31s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 27/58 [23:09<27:54, 54.02s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 28/58 [24:01<26:38, 53.29s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 29/58 [24:51<25:18, 52.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 30/58 [25:39<23:52, 51.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 31/58 [26:31<23:09, 51.45s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 32/58 [27:21<22:02, 50.86s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 33/58 [28:09<20:51, 50.07s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 34/58 [29:01<20:16, 50.71s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 35/58 [29:54<19:38, 51.23s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 36/58 [30:46<18:55, 51.61s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 37/58 [31:36<17:52, 51.08s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 38/58 [32:25<16:49, 50.47s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 39/58 [33:15<15:54, 50.26s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 40/58 [34:04<14:59, 49.99s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 41/58 [34:58<14:30, 51.21s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 42/58 [35:49<13:37, 51.07s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 43/58 [36:39<12:39, 50.62s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/58 [37:30<11:51, 50.83s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/58 [38:24<11:11, 51.65s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 46/58 [39:16<10:24, 52.04s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 47/58 [40:07<09:26, 51.49s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 48/58 [40:59<08:38, 51.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 49/58 [41:52<07:48, 52.00s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50/58 [42:44<06:56, 52.04s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 51/58 [43:34<06:00, 51.50s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 52/58 [44:24<05:06, 51.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/58 [45:16<04:17, 51.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 54/58 [46:10<03:28, 52.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 55/58 [47:03<02:36, 52.17s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 56/58 [47:53<01:43, 51.64s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 57/58 [48:44<00:51, 51.47s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERTScore batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [49:21<00:00, 51.06s/it]\n",
      "Scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5760/5760 [03:05<00:00, 31.13it/s]\n",
      "Metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 90.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[âœ”] Computing RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:   0%|                                  | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86ba8e26c284e1bbeee32c758b4904b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[196]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c226172a4da446c39e41f7d08df7337d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee4ac47480f4b1784e90524c0766534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90f87b8f20045cea282d9be81c184a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:   6%|â–ˆâ–Ž                   | 1/16 [44:03<11:00:48, 2643.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7596a1221c4462ca37576deff2a4f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45724bee65bd45b5af318c7e775d25c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[368]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd5d5d1f1d24ec691d2bd4d74c392b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a8e74f63c249e0bb5c91dcf97c6d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  12%|â–ˆâ–ˆâ–                | 2/16 [1:28:25<10:19:20, 2654.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1126cf937bd4e26932107eb452e69ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af935c543c704d33ae42b20c52824e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[26]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[68]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[271]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5fed8a49e74386b9c1ffa8740ba2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a776d66a9449f4b7b9f3d59f41014b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  19%|â–ˆâ–ˆâ–ˆâ–Š                | 3/16 [2:15:23<9:51:19, 2729.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b404cab6ba442fb48cdb2a34295d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0f87baf0a646c19e13a5aedd2d1efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a31c80da8704bb1af8d1771de9d7fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfe5ae5f205418f93b62335417b3aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 4/16 [2:58:45<8:55:49, 2679.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22b97d8b4dd4f438cb0cad1e6c958f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[180]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[332]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254f1d6d3fb74c808e59f7256c444c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[171]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b682f14de104621b6b8a3df73071aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a61f45f1884137af63f65ca559bc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 5/16 [3:55:16<8:58:12, 2935.64s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7336012a1224f268e3cba2d5150e33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[332]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[335]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[336]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[340]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[348]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aee0e479b1457881e0351df15abb42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[236]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c03de861f842bba57cce65a44b3f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10ba58157be435abe743a8e75c720e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[140]: TimeoutError()\n",
      "RAGAS Evaluation:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 6/16 [4:51:57<8:35:40, 3094.04s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab3d1120f6e490a884118e2753bf4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2396c70fa54ca68684e6407f09cbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2a069161e74198b7cc90fa823915db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b596fdbd0c24f4a83ef108c079ba482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 7/16 [5:47:03<7:54:29, 3163.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ce1a1900424d6b8ebb07473e1bd2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[148]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[152]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[247]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[256]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c301a5dbfc74a1db6d628fef19521c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[387]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93ea9537a7c454597a5edc68ae2c499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd7e5ff0cee48f1a86c5cc02f818ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 8/16 [6:45:18<7:15:49, 3268.65s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d39a0030224ba4b19754a1efa17fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0109507b317543409136763c617db5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[90]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[96]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[236]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[243]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de970287f2904027ae7a44125c776ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[20]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b4ae82402040b99bf982521f2f774f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[187]: TimeoutError()\n",
      "RAGAS Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 9/16 [7:59:53<7:05:21, 3645.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bb5eb67ad942f0a33ecf09106e18a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78282919a7e469fa5a9fb1b98be15bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[100]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[156]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[207]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63654cd89a1e4a6f9c4c8ad0b34b2cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[103]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4586b961e1c42af8d982d12c6efc408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[128]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[143]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[163]: TimeoutError()\n",
      "RAGAS Evaluation:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 10/16 [9:14:47<6:30:46, 3907.68s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc68500cc50b4ebbbc77eefe58b70bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[27]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0a5dc4e89542d29aff73ba0bac4222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[227]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[240]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf96938c0ca34052a9319f3d6f939486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839f8a2a37fc4594bc4e0f246e5a54eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[108]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "RAGAS Evaluation:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/16 [10:31:49<5:43:51, 4126.34s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fd72601ad64b7a80e26fd53bdd3f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[128]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[232]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[236]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15edc17aabef477cab3628a9a724da92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[124]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[196]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b674035e8f43a5a3748f4f5227defe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61987a999b8f46f6bb912a02f8927e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "RAGAS Evaluation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 12/16 [11:48:56<4:45:14, 4278.53s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f430f2e494384fe685807d8465807ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[242]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[294]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[318]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072c5cba076a4c3c8cd89a86bb270a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[42]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[167]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[364]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[372]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[380]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840c22a12e67401e988d6dbe7ca5edcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[68]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[172]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[176]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[288]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[328]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304525542a1a45d385b054c2f4a3876e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[104]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[122]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[188]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[191]: TimeoutError()\n",
      "RAGAS Evaluation:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 13/16 [13:40:38<4:10:37, 5012.66s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb568487c474880bcde6e0f00d1bc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[115]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[264]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faeb3a696d874951ba4832a102114274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[39]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[54]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[74]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[100]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[195]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[230]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[254]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[274]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[371]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b98350261d4c6687893bb02a53d079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[114]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[264]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[288]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[292]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[311]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[319]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[339]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[340]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[360]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[372]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad8d3c91096494f956dbc42466680c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[56]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[78]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[156]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[198]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: TimeoutError()\n",
      "RAGAS Evaluation:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/16 [15:31:12<3:03:24, 5502.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7561fa017543a9a388cb6aafa4a97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[342]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[371]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[376]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[392]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66cb0ee2d5a466e80824597ffb39b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[0]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[4]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[16]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[20]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[31]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[51]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[52]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[55]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[64]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[68]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[95]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[128]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[156]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[168]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[175]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[228]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[248]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[300]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[307]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[343]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[364]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[388]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bec1707fc54bd59a284a7e664e2b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[40]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[56]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[140]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[195]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[264]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[288]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[323]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[332]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b27459963e45c49b27ac40a19734d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[172]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[200]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[204]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[208]: TimeoutError()\n",
      "RAGAS Evaluation:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 15/16 [17:24:28<1:38:12, 5892.39s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0b773b3279429e8734c8d731cba1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[224]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[254]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[280]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[304]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[336]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[360]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[368]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[372]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff30599e20a415cb66c3e8891c4792c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[28]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[115]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[116]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[140]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[164]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[180]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[184]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[188]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[244]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[284]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[292]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[304]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[308]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[315]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[324]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[384]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â³] Rate limit reached. Sleeping for 60.00 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28bd80b51dd4ac7a633eb7caef37fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[124]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[135]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[151]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[152]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[160]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[192]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[204]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[208]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[228]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[244]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937d605fd1704f2c891610d484e79c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[71]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[212]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[228]: TimeoutError()\n",
      "RAGAS Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [19:16:39<00:00, 4337.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Finished RAGAS evaluation safely.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_from_csv(\n",
    "    input_csv_path = \"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/repeated_evaluation_results_OpenAIBM25Gemini_fixed.csv\", \n",
    "    output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/repeated_evaluation_results.csv\",\n",
    "    grouped_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/results_summary.csv\",\n",
    "    metrics_output_path=\"//Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/metrics_and_confusion_matrix.csv\",\n",
    "    classification_report_output_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/classification_report.csv\",\n",
    "    confusion_matrices_csv_path=\"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/confusion_matrix_report.csv\",\n",
    "    ragas_output_path= \"/Users/catarinasilva/Desktop/LLM/Final_eval/OpenAIBM25Gemini/ragas_summary.csv\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
